{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from kan import *\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from treasury_base import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Mo</th>\n",
       "      <th>2 Mo</th>\n",
       "      <th>3 Mo</th>\n",
       "      <th>6 Mo</th>\n",
       "      <th>1 Yr</th>\n",
       "      <th>2 Yr</th>\n",
       "      <th>3 Yr</th>\n",
       "      <th>5 Yr</th>\n",
       "      <th>7 Yr</th>\n",
       "      <th>10 Yr</th>\n",
       "      <th>...</th>\n",
       "      <th>5 Yr_MA5</th>\n",
       "      <th>5 Yr_MA10</th>\n",
       "      <th>7 Yr_MA5</th>\n",
       "      <th>7 Yr_MA10</th>\n",
       "      <th>10 Yr_MA5</th>\n",
       "      <th>10 Yr_MA10</th>\n",
       "      <th>20 Yr_MA5</th>\n",
       "      <th>20 Yr_MA10</th>\n",
       "      <th>30 Yr_MA5</th>\n",
       "      <th>30 Yr_MA10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-16</th>\n",
       "      <td>2.41</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.54</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.73</td>\n",
       "      <td>...</td>\n",
       "      <td>2.542</td>\n",
       "      <td>2.517</td>\n",
       "      <td>2.616</td>\n",
       "      <td>2.587</td>\n",
       "      <td>2.724</td>\n",
       "      <td>2.694</td>\n",
       "      <td>2.910</td>\n",
       "      <td>2.870</td>\n",
       "      <td>3.054</td>\n",
       "      <td>3.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-17</th>\n",
       "      <td>2.41</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.75</td>\n",
       "      <td>...</td>\n",
       "      <td>2.536</td>\n",
       "      <td>2.522</td>\n",
       "      <td>2.612</td>\n",
       "      <td>2.593</td>\n",
       "      <td>2.722</td>\n",
       "      <td>2.701</td>\n",
       "      <td>2.914</td>\n",
       "      <td>2.879</td>\n",
       "      <td>3.062</td>\n",
       "      <td>3.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-18</th>\n",
       "      <td>2.40</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.79</td>\n",
       "      <td>...</td>\n",
       "      <td>2.540</td>\n",
       "      <td>2.543</td>\n",
       "      <td>2.618</td>\n",
       "      <td>2.615</td>\n",
       "      <td>2.724</td>\n",
       "      <td>2.720</td>\n",
       "      <td>2.916</td>\n",
       "      <td>2.897</td>\n",
       "      <td>3.064</td>\n",
       "      <td>3.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-22</th>\n",
       "      <td>2.38</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.74</td>\n",
       "      <td>...</td>\n",
       "      <td>2.560</td>\n",
       "      <td>2.556</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.629</td>\n",
       "      <td>2.740</td>\n",
       "      <td>2.732</td>\n",
       "      <td>2.926</td>\n",
       "      <td>2.909</td>\n",
       "      <td>3.074</td>\n",
       "      <td>3.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>2.37</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.76</td>\n",
       "      <td>...</td>\n",
       "      <td>2.568</td>\n",
       "      <td>2.560</td>\n",
       "      <td>2.648</td>\n",
       "      <td>2.634</td>\n",
       "      <td>2.746</td>\n",
       "      <td>2.736</td>\n",
       "      <td>2.926</td>\n",
       "      <td>2.914</td>\n",
       "      <td>3.074</td>\n",
       "      <td>3.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1 Mo  2 Mo  3 Mo  6 Mo  1 Yr  2 Yr  3 Yr  5 Yr  7 Yr  10 Yr  ...  \\\n",
       "Date                                                                     ...   \n",
       "2019-01-16  2.41  2.40  2.43  2.49  2.57  2.55  2.53  2.54  2.62   2.73  ...   \n",
       "2019-01-17  2.41  2.41  2.42  2.50  2.57  2.56  2.55  2.58  2.66   2.75  ...   \n",
       "2019-01-18  2.40  2.40  2.41  2.50  2.60  2.62  2.60  2.62  2.70   2.79  ...   \n",
       "2019-01-22  2.38  2.40  2.43  2.51  2.59  2.58  2.55  2.57  2.65   2.74  ...   \n",
       "2019-01-23  2.37  2.38  2.41  2.51  2.59  2.58  2.57  2.59  2.66   2.76  ...   \n",
       "\n",
       "            5 Yr_MA5  5 Yr_MA10  7 Yr_MA5  7 Yr_MA10  10 Yr_MA5  10 Yr_MA10  \\\n",
       "Date                                                                          \n",
       "2019-01-16     2.542      2.517     2.616      2.587      2.724       2.694   \n",
       "2019-01-17     2.536      2.522     2.612      2.593      2.722       2.701   \n",
       "2019-01-18     2.540      2.543     2.618      2.615      2.724       2.720   \n",
       "2019-01-22     2.560      2.556     2.638      2.629      2.740       2.732   \n",
       "2019-01-23     2.568      2.560     2.648      2.634      2.746       2.736   \n",
       "\n",
       "            20 Yr_MA5  20 Yr_MA10  30 Yr_MA5  30 Yr_MA10  \n",
       "Date                                                      \n",
       "2019-01-16      2.910       2.870      3.054       3.013  \n",
       "2019-01-17      2.914       2.879      3.062       3.023  \n",
       "2019-01-18      2.916       2.897      3.064       3.038  \n",
       "2019-01-22      2.926       2.909      3.074       3.049  \n",
       "2019-01-23      2.926       2.914      3.074       3.056  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_LIST = [5, 10]\n",
    "LAG = 1\n",
    "\n",
    "def train_mse():\n",
    "    predictions = model(dataset['train_input'])  # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['train_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5  # Return scalar MSE value\n",
    "\n",
    "def test_mse():\n",
    "    predictions = model(dataset['test_input']) # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['test_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5\n",
    "    \n",
    "df_ma = ma_data_retrieval(window_list=WINDOW_LIST, lag=LAG)\n",
    "df_ma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 1\n",
    "LENGTH = len(df_ma)\n",
    "TARGETS = df_ma.columns[:12]\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = {'train_mse': [], 'test_mse': [], 'naive_mse': []}\n",
    "\n",
    "for cnt in range(0, 20, 5):\n",
    "    print()\n",
    "    print('WINDOW SLIDING: ', cnt)\n",
    "\n",
    "    df_window = df_ma[(LENGTH-cnt-120):(LENGTH-cnt)]\n",
    "    # Prepare data\n",
    "    X, y = df_window.drop(columns=TARGETS), df_window[TARGETS]\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = pd.DataFrame(scaler.fit_transform(X))\n",
    "\n",
    "    n_inputs = X.shape[1]\n",
    "    n_outputs = y.shape[1]\n",
    "\n",
    "    X_train, X_test = X[:-TEST_SIZE], X[-TEST_SIZE:]\n",
    "    y_train, y_test = y[:-TEST_SIZE], y[-TEST_SIZE:]\n",
    "\n",
    "    dataset = dict()\n",
    "    dtype = torch.get_default_dtype()\n",
    "    dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "    dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "    dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype).to(device)\n",
    "    dataset['test_label'] = torch.from_numpy(y_test.values).type(dtype).to(device)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = KAN(width=[n_inputs, 32, n_outputs], grid=3, k=2, seed=42, device=device)\n",
    "\n",
    "    # Train the model and compute metrics\n",
    "    results = model.fit(dataset, opt=\"Adam\", lamb=0.001, lr=0.001, steps=1500, metrics=(train_mse, test_mse))\n",
    "    df_naive = pd.DataFrame([y_train.iloc[-1]] * TEST_SIZE, columns=y_train.columns)\n",
    "        \n",
    "    # Store the metrics\n",
    "    train_error = results['train_mse'][-1]\n",
    "    test_error = results['test_mse'][-1]\n",
    "    naive_error = mean_squared_error(df_naive, y_test, squared=False)\n",
    "\n",
    "    fold_results['train_mse'].append(train_error)\n",
    "    fold_results['test_mse'].append(test_error)\n",
    "    fold_results['naive_mse'].append(naive_error)\n",
    "\n",
    "    # Calculate average metrics across all windows\n",
    "    print(f'Fold Train MSE: {train_error}')\n",
    "    print(f'Fold Test MSE: {test_error}')\n",
    "    print(f'Naive Test MSE: {naive_error}')\n",
    "\n",
    "avg_train_mse = np.mean(fold_results['train_mse'])\n",
    "avg_test_mse = np.mean(fold_results['test_mse'])\n",
    "avg_naive_mse = np.mean(fold_results['naive_mse'])\n",
    "\n",
    "print()\n",
    "print(\"Sliding Window Cross-Validation Results\")\n",
    "print(f\"Average Train MSE: {avg_train_mse}\")\n",
    "print(f\"Average Test MSE: {avg_test_mse}\")\n",
    "print(f\"Average Naive MSE: {avg_naive_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params  # E.g. {'x': 2.002108042}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 2)  # Number of layers in the network\n",
    "    layer_sizes = [trial.suggest_int(f'n_units_l{i}', 16, 64, step=16) for i in range(n_layers)]\n",
    "    grid = trial.suggest_int('grid', 2, 4)          # Example parameter for KAN\n",
    "    lamb = trial.suggest_float('lamb', 1e-4, 1e-2, log=True)  # Regularization rate\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)       # Learning rate\n",
    "    steps = trial.suggest_int('steps', 500, 2000, step=500)   # Training steps\n",
    "\n",
    "    # Model architecture\n",
    "    width = [n_inputs] + layer_sizes + [n_outputs]\n",
    "\n",
    "    # Initialize dataset\n",
    "    dataset = dict()\n",
    "    dtype = torch.get_default_dtype()\n",
    "    dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "    dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "    dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype).to(device)\n",
    "    dataset['test_label'] = torch.from_numpy(y_test.values).type(dtype).to(device)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = KAN(width=width, grid=grid, k=2, seed=42, device=device)\n",
    "\n",
    "    # Train the model\n",
    "    results = model.fit(\n",
    "        dataset, \n",
    "        opt=\"Adam\", \n",
    "        lamb=lamb, \n",
    "        lr=lr, \n",
    "        steps=steps, \n",
    "        metrics=(train_mse, test_mse)\n",
    "    )\n",
    "    \n",
    "    # Retrieve the metric (e.g., test MSE) from the results\n",
    "    test_mse_value = results['test_mse']\n",
    "    return test_mse_value  # Minimize test MSE\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best parameters and results\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best test MSE:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
