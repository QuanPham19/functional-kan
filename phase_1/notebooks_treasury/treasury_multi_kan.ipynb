{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from kan import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>4.72</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.41</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>4.74</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.27</td>\n",
       "      <td>...</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-04</th>\n",
       "      <td>4.74</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.61</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.30</td>\n",
       "      <td>...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-05</th>\n",
       "      <td>4.76</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-06</th>\n",
       "      <td>4.76</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9  ...  \\\n",
       "Date                                                                    ...   \n",
       "2024-12-02  4.72  4.67  4.63  4.46  4.42  4.37  4.32  4.30  4.35  4.41  ...   \n",
       "2024-12-03  4.74  4.67  4.62  4.46  4.37  4.21  4.21  4.17  4.21  4.27  ...   \n",
       "2024-12-04  4.74  4.67  4.61  4.45  4.37  4.21  4.21  4.17  4.24  4.30  ...   \n",
       "2024-12-05  4.76  4.70  4.60  4.43  4.34  4.19  4.17  4.11  4.17  4.25  ...   \n",
       "2024-12-06  4.76  4.69  4.58  4.42  4.30  4.13  4.10  4.05  4.10  4.18  ...   \n",
       "\n",
       "             y_3   y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  y_12  \n",
       "Date                                                                    \n",
       "2024-12-02  4.51  4.43  4.30  4.17  4.11  4.08  4.13  4.19  4.46  4.36  \n",
       "2024-12-03  4.49  4.40  4.27  4.17  4.13  4.11  4.17  4.23  4.50  4.40  \n",
       "2024-12-04  4.47  4.38  4.23  4.13  4.09  4.07  4.13  4.19  4.45  4.35  \n",
       "2024-12-05  4.46  4.38  4.23  4.15  4.10  4.07  4.12  4.17  4.43  4.33  \n",
       "2024-12-06  4.42  4.34  4.19  4.10  4.05  4.03  4.09  4.15  4.42  4.34  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def treasury_data_retrieval():\n",
    "    df = pd.read_csv('../data/us_treasury_rates_large.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = treasury_data_retrieval()\n",
    "\n",
    "n = len(df)\n",
    "h = 5\n",
    "\n",
    "df_flat = pd.DataFrame()\n",
    "for id in range(h, n):\n",
    "    row = df.iloc[(id-h):(id), 1:].stack().reset_index(drop=True).to_frame().T\n",
    "    df_flat = pd.concat([df_flat, row], ignore_index=True)\n",
    "\n",
    "for id in range(1, 13):\n",
    "    df_flat[f'y_{id}'] = df.iloc[h:, id].values\n",
    "\n",
    "df_flat['Date'] = df['Date'].iloc[h:].values\n",
    "# df_flat.dropna(inplace=True)\n",
    "df_flat.columns = df_flat.columns.astype(str)\n",
    "df_flat.set_index('Date', inplace=True)\n",
    "\n",
    "# df_flat = df_flat.iloc[:-10]\n",
    "df_flat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mse():\n",
    "    predictions = model(dataset['train_input'])  # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['train_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5  # Return scalar MSE value\n",
    "\n",
    "def test_mse():\n",
    "    predictions = model(dataset['test_input']) # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['test_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the sliding window\n",
    "test_size = 10\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = {'train_mse': [], 'test_mse': []}\n",
    "\n",
    "# Prepare data\n",
    "X, y = df_flat.iloc[:, :-12], df_flat.iloc[:, -12:]\n",
    "n_inputs = X.shape[1]\n",
    "n_outputs = y.shape[1]\n",
    "\n",
    "X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "dataset = dict()\n",
    "dtype = torch.get_default_dtype()\n",
    "dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "dataset['test_input'] = torch.from_numpy(X_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "dataset['test_label'] = torch.from_numpy(y_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "\n",
    "# Initialize the model\n",
    "model = KAN(width=[n_inputs, 20, n_outputs], grid=3, k=2, seed=42, device=device)\n",
    "\n",
    "# Train the model and compute metrics\n",
    "results = model.fit(dataset, opt=\"Adam\", lamb=0.001, lr=0.001, steps=1000, metrics=(train_mse, test_mse))\n",
    "\n",
    "\n",
    "feature = dataset['test_input']\n",
    "output_list = list()\n",
    "for id in range(1, test_size + 1):\n",
    "    new = model(feature).cpu().detach().numpy().flatten()\n",
    "    output_list.append(new)\n",
    "\n",
    "    old = feature.cpu().detach().numpy().flatten()[(n_outputs):]\n",
    "    feature = torch.from_numpy(np.append(old, new).reshape(1, -1)).type(dtype).to(device)\n",
    "    \n",
    "    \n",
    "# Store the metrics\n",
    "fold_results['train_mse'].append(results['train_mse'][-1])\n",
    "fold_results['test_mse'].append(results['test_mse'][-1])\n",
    "\n",
    "# Calculate average metrics across all windows\n",
    "avg_train_mse = np.mean(fold_results['train_mse'])\n",
    "avg_test_mse = np.mean(fold_results['test_mse'])\n",
    "\n",
    "print(\"Sliding Window Cross-Validation Results\")\n",
    "print(f\"Average Train MSE: {avg_train_mse}\")\n",
    "print(f\"Average Test MSE: {mean_squared_error(output_list, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WINDOW SLIDING:  0\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 4.68e+00 | test_loss: 4.24e+00 | reg: 7.46e+01 | :   0%|     | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 7.62e-02 | test_loss: 1.17e-01 | reg: 3.05e+01 | : 100%|█| 1000/1000 [00:36<00:00, 27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.07700548542964239\n",
      "Fold Test MSE: 0.08429906089615313\n",
      "Naive Test MSE: 0.031666666666666655\n",
      "\n",
      "WINDOW SLIDING:  1\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.78e-01 | test_loss: 2.83e-01 | reg: 6.63e+01 | :  13%|▏| 133/1000 [00:05<00:33, 25.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m KAN(width\u001b[38;5;241m=\u001b[39m[n_inputs, \u001b[38;5;241m16\u001b[39m, n_outputs], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model and compute metrics\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_mse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_mse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m feature \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_input\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     38\u001b[0m output_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/kan/MultKAN.py:1575\u001b[0m, in \u001b[0;36mMultKAN.fit\u001b[0;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, singularity_avoiding, y_th, reg_metric, display_metrics)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metrics \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(metrics)):\n\u001b[0;32m-> 1575\u001b[0m         results[metrics[i]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m   1577\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39msqrt(train_loss)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m   1578\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39msqrt(test_loss)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mtrain_mse\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_mse\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Model predictions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     mse \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(predictions, dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_label\u001b[39m\u001b[38;5;124m'\u001b[39m], reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Compute MSE\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mse \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/kan/MultKAN.py:800\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[0;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[0;32m--> 800\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;66;03m#print(preacts, postacts_numerical, postspline)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/kan/KANLayer.py:161\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    157\u001b[0m y \u001b[38;5;241m=\u001b[39m coef2curve(x_eval\u001b[38;5;241m=\u001b[39mx, grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid, coef\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\n\u001b[1;32m    159\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m base[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_sp\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m y\n\u001b[1;32m    162\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m y\n\u001b[1;32m    164\u001b[0m postacts \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1716\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1709\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1718\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the sliding window\n",
    "test_size = 5\n",
    "df_length = len(df_flat)\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = {'train_mse': [], 'test_mse': [], 'naive_mse': []}\n",
    "\n",
    "for cnt in range(0, 20, 5):\n",
    "    print()\n",
    "    print('WINDOW SLIDING: ', cnt)\n",
    "\n",
    "    df_window = df_flat[(df_length-cnt-250):(df_length-cnt)]\n",
    "    # Prepare data\n",
    "    X, y = df_window.iloc[:, :-12], df_window.iloc[:, -12:]\n",
    "\n",
    "    n_inputs = X.shape[1]\n",
    "    n_outputs = y.shape[1]\n",
    "\n",
    "    X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "    y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "    dataset = dict()\n",
    "    dtype = torch.get_default_dtype()\n",
    "    dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "    dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "    dataset['test_input'] = torch.from_numpy(X_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "    dataset['test_label'] = torch.from_numpy(y_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = KAN(width=[n_inputs, 20, n_outputs], grid=3, k=2, seed=42, device=device)\n",
    "\n",
    "    # Train the model and compute metrics\n",
    "    results = model.fit(dataset, opt=\"Adam\", lamb=0.001, lr=0.001, steps=1000, metrics=(train_mse, test_mse))\n",
    "\n",
    "    feature = dataset['test_input']\n",
    "    output_list = list()\n",
    "    for id in range(1, test_size + 1):\n",
    "        new = model(feature).cpu().detach().numpy().flatten()\n",
    "        output_list.append(new)\n",
    "\n",
    "        old = feature.cpu().detach().numpy().flatten()[(n_outputs):]\n",
    "        feature = torch.from_numpy(np.append(old, new).reshape(1, -1)).type(dtype).to(device)\n",
    "    \n",
    "    df_naive = pd.DataFrame([y_train.iloc[-1]] * test_size, columns=y_train.columns)\n",
    "        \n",
    "    # Store the metrics\n",
    "    train_error = results['train_mse'][-1]\n",
    "    test_error = mean_squared_error(output_list, y_test, squared=False)\n",
    "    naive_error = mean_squared_error(df_naive, y_test, squared=False)\n",
    "\n",
    "    fold_results['train_mse'].append(train_error)\n",
    "    fold_results['test_mse'].append(test_error)\n",
    "    fold_results['naive_mse'].append(naive_error)\n",
    "\n",
    "    # Calculate average metrics across all windows\n",
    "    print(f'Fold Train MSE: {train_error}')\n",
    "    print(f'Fold Test MSE: {test_error}')\n",
    "    print(f'Naive Test MSE: {naive_error}')\n",
    "\n",
    "avg_train_mse = np.mean(fold_results['train_mse'])\n",
    "avg_test_mse = np.mean(fold_results['test_mse'])\n",
    "avg_naive_mse = np.mean(fold_results['naive_mse'])\n",
    "\n",
    "print(\"Sliding Window Cross-Validation Results\")\n",
    "print(f\"Average Train MSE: {avg_train_mse}\")\n",
    "print(f\"Average Test MSE: {avg_test_mse}\")\n",
    "print(f\"Average Naive MSE: {avg_naive_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.025754166666666644)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive = pd.DataFrame([y_train.iloc[-1]] * test_size, columns=y_train.columns)\n",
    "mean_squared_error(df_naive, y_test)\n",
    "# df_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.808254</td>\n",
       "      <td>4.722639</td>\n",
       "      <td>4.730283</td>\n",
       "      <td>4.386444</td>\n",
       "      <td>4.244575</td>\n",
       "      <td>4.121847</td>\n",
       "      <td>4.052503</td>\n",
       "      <td>4.054090</td>\n",
       "      <td>4.125195</td>\n",
       "      <td>4.168106</td>\n",
       "      <td>4.521195</td>\n",
       "      <td>4.460731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.425504</td>\n",
       "      <td>7.759623</td>\n",
       "      <td>7.564955</td>\n",
       "      <td>6.729259</td>\n",
       "      <td>7.209680</td>\n",
       "      <td>6.702704</td>\n",
       "      <td>6.475952</td>\n",
       "      <td>6.409134</td>\n",
       "      <td>5.845021</td>\n",
       "      <td>6.518092</td>\n",
       "      <td>7.001816</td>\n",
       "      <td>6.102906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.688330</td>\n",
       "      <td>12.754750</td>\n",
       "      <td>11.603767</td>\n",
       "      <td>11.206963</td>\n",
       "      <td>11.773730</td>\n",
       "      <td>10.609055</td>\n",
       "      <td>9.988644</td>\n",
       "      <td>9.223608</td>\n",
       "      <td>7.769438</td>\n",
       "      <td>9.584902</td>\n",
       "      <td>10.734335</td>\n",
       "      <td>9.246078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.595896</td>\n",
       "      <td>20.126341</td>\n",
       "      <td>18.872407</td>\n",
       "      <td>18.177391</td>\n",
       "      <td>19.066755</td>\n",
       "      <td>17.503062</td>\n",
       "      <td>15.908176</td>\n",
       "      <td>14.377980</td>\n",
       "      <td>12.521150</td>\n",
       "      <td>15.198067</td>\n",
       "      <td>16.661805</td>\n",
       "      <td>14.342094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.693696</td>\n",
       "      <td>32.786344</td>\n",
       "      <td>30.992696</td>\n",
       "      <td>29.877886</td>\n",
       "      <td>31.374907</td>\n",
       "      <td>28.604893</td>\n",
       "      <td>25.897076</td>\n",
       "      <td>22.886119</td>\n",
       "      <td>20.458540</td>\n",
       "      <td>24.664812</td>\n",
       "      <td>26.611204</td>\n",
       "      <td>23.094519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5   \\\n",
       "0   4.808254   4.722639   4.730283   4.386444   4.244575   4.121847   \n",
       "1   7.425504   7.759623   7.564955   6.729259   7.209680   6.702704   \n",
       "2  12.688330  12.754750  11.603767  11.206963  11.773730  10.609055   \n",
       "3  20.595896  20.126341  18.872407  18.177391  19.066755  17.503062   \n",
       "4  33.693696  32.786344  30.992696  29.877886  31.374907  28.604893   \n",
       "\n",
       "          6          7          8          9          10         11  \n",
       "0   4.052503   4.054090   4.125195   4.168106   4.521195   4.460731  \n",
       "1   6.475952   6.409134   5.845021   6.518092   7.001816   6.102906  \n",
       "2   9.988644   9.223608   7.769438   9.584902  10.734335   9.246078  \n",
       "3  15.908176  14.377980  12.521150  15.198067  16.661805  14.342094  \n",
       "4  25.897076  22.886119  20.458540  24.664812  26.611204  23.094519  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-09</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10</th>\n",
       "      <td>4.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-11</th>\n",
       "      <td>4.97</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-15</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>4.91</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-17</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18</th>\n",
       "      <td>4.92</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-21</th>\n",
       "      <td>4.92</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>4.89</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>4.88</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_1   y_2   y_3   y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  \\\n",
       "Date                                                                           \n",
       "2024-10-09  4.93  4.84  4.75  4.46  4.24  3.99  3.89  3.91  3.97  4.06  4.41   \n",
       "2024-10-10  4.98  4.84  4.75  4.45  4.22  3.98  3.88  3.91  3.99  4.09  4.44   \n",
       "2024-10-11  4.97  4.82  4.73  4.44  4.18  3.95  3.85  3.88  3.97  4.08  4.44   \n",
       "2024-10-15  4.93  4.82  4.73  4.42  4.18  3.95  3.86  3.86  3.93  4.03  4.37   \n",
       "2024-10-16  4.91  4.80  4.72  4.42  4.17  3.93  3.84  3.84  3.92  4.02  4.36   \n",
       "2024-10-17  4.93  4.83  4.74  4.45  4.21  3.96  3.89  3.90  3.99  4.09  4.44   \n",
       "2024-10-18  4.92  4.82  4.73  4.45  4.19  3.95  3.86  3.88  3.97  4.08  4.44   \n",
       "2024-10-21  4.92  4.82  4.73  4.47  4.24  4.02  3.95  3.98  4.07  4.19  4.54   \n",
       "2024-10-22  4.89  4.81  4.72  4.47  4.24  4.03  3.98  4.00  4.10  4.20  4.55   \n",
       "2024-10-23  4.88  4.80  4.73  4.48  4.27  4.07  4.03  4.05  4.14  4.24  4.58   \n",
       "\n",
       "            y_12  \n",
       "Date              \n",
       "2024-10-09  4.34  \n",
       "2024-10-10  4.38  \n",
       "2024-10-11  4.39  \n",
       "2024-10-15  4.32  \n",
       "2024-10-16  4.30  \n",
       "2024-10-17  4.39  \n",
       "2024-10-18  4.38  \n",
       "2024-10-21  4.49  \n",
       "2024-10-22  4.49  \n",
       "2024-10-23  4.51  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_1   y_2   y_3   y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  \\\n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "\n",
       "            y_12  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module kan.MultKAN:\n",
      "\n",
      "fit(dataset, opt='LBFGS', steps=100, log=1, lamb=0.0, lamb_l1=1.0, lamb_entropy=2.0, lamb_coef=0.0, lamb_coefdiff=0.0, update_grid=True, grid_update_num=10, loss_fn=None, lr=1.0, start_grid_update_step=-1, stop_grid_update_step=50, batch=-1, metrics=None, save_fig=False, in_vars=None, out_vars=None, beta=3, save_fig_freq=1, img_folder='./video', singularity_avoiding=False, y_th=1000.0, reg_metric='edge_forward_spline_n', display_metrics=None) method of kan.MultKAN.MultKAN instance\n",
      "    training\n",
      "\n",
      "    Args:\n",
      "    -----\n",
      "        dataset : dic\n",
      "            contains dataset['train_input'], dataset['train_label'], dataset['test_input'], dataset['test_label']\n",
      "        opt : str\n",
      "            \"LBFGS\" or \"Adam\"\n",
      "        steps : int\n",
      "            training steps\n",
      "        log : int\n",
      "            logging frequency\n",
      "        lamb : float\n",
      "            overall penalty strength\n",
      "        lamb_l1 : float\n",
      "            l1 penalty strength\n",
      "        lamb_entropy : float\n",
      "            entropy penalty strength\n",
      "        lamb_coef : float\n",
      "            coefficient magnitude penalty strength\n",
      "        lamb_coefdiff : float\n",
      "            difference of nearby coefficits (smoothness) penalty strength\n",
      "        update_grid : bool\n",
      "            If True, update grid regularly before stop_grid_update_step\n",
      "        grid_update_num : int\n",
      "            the number of grid updates before stop_grid_update_step\n",
      "        start_grid_update_step : int\n",
      "            no grid updates before this training step\n",
      "        stop_grid_update_step : int\n",
      "            no grid updates after this training step\n",
      "        loss_fn : function\n",
      "            loss function\n",
      "        lr : float\n",
      "            learning rate\n",
      "        batch : int\n",
      "            batch size, if -1 then full.\n",
      "        save_fig_freq : int\n",
      "            save figure every (save_fig_freq) steps\n",
      "        singularity_avoiding : bool\n",
      "            indicate whether to avoid singularity for the symbolic part\n",
      "        y_th : float\n",
      "            singularity threshold (anything above the threshold is considered singular and is softened in some ways)\n",
      "        reg_metric : str\n",
      "            regularization metric. Choose from {'edge_forward_spline_n', 'edge_forward_spline_u', 'edge_forward_sum', 'edge_backward', 'node_backward'}\n",
      "        metrics : a list of metrics (as functions)\n",
      "            the metrics to be computed in training\n",
      "        display_metrics : a list of functions\n",
      "            the metric to be displayed in tqdm progress bar\n",
      "\n",
      "    Returns:\n",
      "    --------\n",
      "        results : dic\n",
      "            results['train_loss'], 1D array of training losses (RMSE)\n",
      "            results['test_loss'], 1D array of test losses (RMSE)\n",
      "            results['reg'], 1D array of regularization\n",
      "            other metrics specified in metrics\n",
      "\n",
      "    Example\n",
      "    -------\n",
      "    >>> from kan import *\n",
      "    >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.3, seed=2)\n",
      "    >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
      "    >>> dataset = create_dataset(f, n_var=2)\n",
      "    >>> model.fit(dataset, opt='LBFGS', steps=20, lamb=0.001);\n",
      "    >>> model.plot()\n",
      "    # Most examples in toturals involve the fit() method. Please check them for useness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
