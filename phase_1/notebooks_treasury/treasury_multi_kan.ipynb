{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from kan import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>4.72</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.41</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>4.74</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.27</td>\n",
       "      <td>...</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-04</th>\n",
       "      <td>4.74</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.61</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.30</td>\n",
       "      <td>...</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-05</th>\n",
       "      <td>4.76</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-06</th>\n",
       "      <td>4.76</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9  ...  \\\n",
       "Date                                                                    ...   \n",
       "2024-12-02  4.72  4.67  4.63  4.46  4.42  4.37  4.32  4.30  4.35  4.41  ...   \n",
       "2024-12-03  4.74  4.67  4.62  4.46  4.37  4.21  4.21  4.17  4.21  4.27  ...   \n",
       "2024-12-04  4.74  4.67  4.61  4.45  4.37  4.21  4.21  4.17  4.24  4.30  ...   \n",
       "2024-12-05  4.76  4.70  4.60  4.43  4.34  4.19  4.17  4.11  4.17  4.25  ...   \n",
       "2024-12-06  4.76  4.69  4.58  4.42  4.30  4.13  4.10  4.05  4.10  4.18  ...   \n",
       "\n",
       "             y_3   y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  y_12  \n",
       "Date                                                                    \n",
       "2024-12-02  4.51  4.43  4.30  4.17  4.11  4.08  4.13  4.19  4.46  4.36  \n",
       "2024-12-03  4.49  4.40  4.27  4.17  4.13  4.11  4.17  4.23  4.50  4.40  \n",
       "2024-12-04  4.47  4.38  4.23  4.13  4.09  4.07  4.13  4.19  4.45  4.35  \n",
       "2024-12-05  4.46  4.38  4.23  4.15  4.10  4.07  4.12  4.17  4.43  4.33  \n",
       "2024-12-06  4.42  4.34  4.19  4.10  4.05  4.03  4.09  4.15  4.42  4.34  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def treasury_data_retrieval():\n",
    "    df = pd.read_csv('../data/us_treasury_rates_large.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = treasury_data_retrieval()\n",
    "\n",
    "n = len(df)\n",
    "h = 5\n",
    "\n",
    "df_flat = pd.DataFrame()\n",
    "for id in range(h, n):\n",
    "    row = df.iloc[(id-h):(id), 1:].stack().reset_index(drop=True).to_frame().T\n",
    "    df_flat = pd.concat([df_flat, row], ignore_index=True)\n",
    "\n",
    "for id in range(1, 13):\n",
    "    df_flat[f'y_{id}'] = df.iloc[h:, id].values\n",
    "\n",
    "df_flat['Date'] = df['Date'].iloc[h:].values\n",
    "# df_flat.dropna(inplace=True)\n",
    "df_flat.columns = df_flat.columns.astype(str)\n",
    "df_flat.set_index('Date', inplace=True)\n",
    "\n",
    "# df_flat = df_flat.iloc[:-10]\n",
    "df_flat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mse():\n",
    "    predictions = model(dataset['train_input'])  # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['train_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5  # Return scalar MSE value\n",
    "\n",
    "def test_mse():\n",
    "    predictions = model(dataset['test_input']) # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['test_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the sliding window\n",
    "test_size = 10\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = {'train_mse': [], 'test_mse': []}\n",
    "\n",
    "# Prepare data\n",
    "X, y = df_flat.iloc[:, :-12], df_flat.iloc[:, -12:]\n",
    "n_inputs = X.shape[1]\n",
    "n_outputs = y.shape[1]\n",
    "\n",
    "X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "dataset = dict()\n",
    "dtype = torch.get_default_dtype()\n",
    "dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "dataset['test_input'] = torch.from_numpy(X_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "dataset['test_label'] = torch.from_numpy(y_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "\n",
    "# Initialize the model\n",
    "model = KAN(width=[n_inputs, 20, n_outputs], grid=3, k=2, seed=42, device=device)\n",
    "\n",
    "# Train the model and compute metrics\n",
    "results = model.fit(dataset, opt=\"Adam\", lamb=0.001, lr=0.001, steps=1000, metrics=(train_mse, test_mse))\n",
    "\n",
    "\n",
    "feature = dataset['test_input']\n",
    "output_list = list()\n",
    "for id in range(1, test_size + 1):\n",
    "    new = model(feature).cpu().detach().numpy().flatten()\n",
    "    output_list.append(new)\n",
    "\n",
    "    old = feature.cpu().detach().numpy().flatten()[(n_outputs):]\n",
    "    feature = torch.from_numpy(np.append(old, new).reshape(1, -1)).type(dtype).to(device)\n",
    "    \n",
    "    \n",
    "# Store the metrics\n",
    "fold_results['train_mse'].append(results['train_mse'][-1])\n",
    "fold_results['test_mse'].append(results['test_mse'][-1])\n",
    "\n",
    "# Calculate average metrics across all windows\n",
    "avg_train_mse = np.mean(fold_results['train_mse'])\n",
    "avg_test_mse = np.mean(fold_results['test_mse'])\n",
    "\n",
    "print(\"Sliding Window Cross-Validation Results\")\n",
    "print(f\"Average Train MSE: {avg_train_mse}\")\n",
    "print(f\"Average Test MSE: {mean_squared_error(output_list, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WINDOW SLIDING:  0\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                         | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.11e-02 | test_loss: 7.93e-02 | reg: 2.52e+01 | : 100%|█| 1000/1000 [00:24<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06157215903120201\n",
      "Fold Test MSE: 0.10514085492622509\n",
      "Naive Test MSE: 0.05929291173832928\n",
      "\n",
      "WINDOW SLIDING:  10\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.40e-02 | test_loss: 1.13e-01 | reg: 2.67e+01 | : 100%|█| 1000/1000 [00:24<00:00, 40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.0641009338351672\n",
      "Fold Test MSE: 0.11562183284179596\n",
      "Naive Test MSE: 0.02755751680925565\n",
      "\n",
      "WINDOW SLIDING:  20\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.84e-02 | test_loss: 1.49e-01 | reg: 2.51e+01 | : 100%|█| 1000/1000 [00:24<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06841495630266119\n",
      "Fold Test MSE: 0.23716508353150023\n",
      "Naive Test MSE: 0.06160194700747588\n",
      "\n",
      "WINDOW SLIDING:  30\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.78e-02 | test_loss: 1.19e-01 | reg: 2.46e+01 | : 100%|█| 1000/1000 [00:23<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06778131330347706\n",
      "Fold Test MSE: 0.19580298204468627\n",
      "Naive Test MSE: 0.09433258975805352\n",
      "\n",
      "WINDOW SLIDING:  40\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.66e-02 | test_loss: 9.11e-02 | reg: 2.31e+01 | : 100%|█| 1000/1000 [00:24<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06658785914699039\n",
      "Fold Test MSE: 0.18453306179786477\n",
      "Naive Test MSE: 0.16690425093515834\n",
      "\n",
      "WINDOW SLIDING:  50\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.51e-02 | test_loss: 1.22e-01 | reg: 1.90e+01 | : 100%|█| 1000/1000 [00:24<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06508849795053559\n",
      "Fold Test MSE: 0.12834315628206047\n",
      "Naive Test MSE: 0.10500833376365615\n",
      "\n",
      "WINDOW SLIDING:  60\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.63e-02 | test_loss: 1.65e-01 | reg: 1.52e+01 | : 100%|█| 1000/1000 [00:23<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06639326955107715\n",
      "Fold Test MSE: 0.2257274681040413\n",
      "Naive Test MSE: 0.13723092956781716\n",
      "\n",
      "WINDOW SLIDING:  70\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.86e-02 | test_loss: 1.17e-01 | reg: 1.29e+01 | : 100%|█| 1000/1000 [00:24<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06856430708631708\n",
      "Fold Test MSE: 0.11802222913976555\n",
      "Naive Test MSE: 0.06531569802328573\n",
      "\n",
      "WINDOW SLIDING:  80\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.50e-02 | test_loss: 1.88e-01 | reg: 7.44e+00 | : 100%|█| 1000/1000 [00:24<00:00, 41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.06491272506431928\n",
      "Fold Test MSE: 0.20542511840625902\n",
      "Naive Test MSE: 0.11539946218974749\n",
      "\n",
      "WINDOW SLIDING:  90\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 6.02e-02 | test_loss: 1.03e-01 | reg: 5.85e+00 | : 100%|█| 1000/1000 [00:24<00:00, 40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold Train MSE: 0.060227873010616655\n",
      "Fold Test MSE: 0.11060009087270876\n",
      "Naive Test MSE: 0.05290306367836689\n",
      "\n",
      "Sliding Window Cross-Validation Results\n",
      "Average Train MSE: 0.06536438942823636\n",
      "Average Test MSE: 0.16263818779469075\n",
      "Average Naive MSE: 0.08855467034711462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the sliding window\n",
    "test_size = 5\n",
    "df_length = len(df_flat)\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = {'train_mse': [], 'test_mse': [], 'naive_mse': []}\n",
    "\n",
    "for cnt in range(0, 100, 10):\n",
    "    print()\n",
    "    print('WINDOW SLIDING: ', cnt)\n",
    "\n",
    "    df_window = df_flat[(df_length-cnt-100):(df_length-cnt)]\n",
    "    # Prepare data\n",
    "    X, y = df_window.iloc[:, :-12], df_window.iloc[:, -12:]\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # X = pd.DataFrame(scaler.fit_transform(X))\n",
    "\n",
    "    n_inputs = X.shape[1]\n",
    "    n_outputs = y.shape[1]\n",
    "\n",
    "    X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "    y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "    dataset = dict()\n",
    "    dtype = torch.get_default_dtype()\n",
    "    dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "    dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "    dataset['test_input'] = torch.from_numpy(X_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "    dataset['test_label'] = torch.from_numpy(y_test.iloc[0, :].values.reshape(1, -1)).type(dtype).to(device)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = KAN(width=[n_inputs, 20, n_outputs], grid=3, k=2, seed=42, device=device)\n",
    "\n",
    "    # Train the model and compute metrics\n",
    "    results = model.fit(dataset, opt=\"Adam\", lamb=0.001, lr=0.001, steps=1000, metrics=(train_mse, test_mse))\n",
    "\n",
    "    feature = dataset['test_input']\n",
    "    output_list = list()\n",
    "    for id in range(1, test_size + 1):\n",
    "        new = model(feature).cpu().detach().numpy().flatten()\n",
    "        output_list.append(new)\n",
    "\n",
    "        old = feature.cpu().detach().numpy().flatten()[(n_outputs):]\n",
    "        feature = torch.from_numpy(np.append(old, new).reshape(1, -1)).type(dtype).to(device)\n",
    "    \n",
    "    df_naive = pd.DataFrame([y_train.iloc[-1]] * test_size, columns=y_train.columns)\n",
    "        \n",
    "    # Store the metrics\n",
    "    train_error = results['train_mse'][-1]\n",
    "    test_error = mean_squared_error(output_list, y_test, squared=False)\n",
    "    naive_error = mean_squared_error(df_naive, y_test, squared=False)\n",
    "\n",
    "    fold_results['train_mse'].append(train_error)\n",
    "    fold_results['test_mse'].append(test_error)\n",
    "    fold_results['naive_mse'].append(naive_error)\n",
    "\n",
    "    # Calculate average metrics across all windows\n",
    "    print(f'Fold Train MSE: {train_error}')\n",
    "    print(f'Fold Test MSE: {test_error}')\n",
    "    print(f'Naive Test MSE: {naive_error}')\n",
    "\n",
    "avg_train_mse = np.mean(fold_results['train_mse'])\n",
    "avg_test_mse = np.mean(fold_results['test_mse'])\n",
    "avg_naive_mse = np.mean(fold_results['naive_mse'])\n",
    "\n",
    "print()\n",
    "print(\"Sliding Window Cross-Validation Results\")\n",
    "print(f\"Average Train MSE: {avg_train_mse}\")\n",
    "print(f\"Average Test MSE: {avg_test_mse}\")\n",
    "print(f\"Average Naive MSE: {avg_naive_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.025754166666666644)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive = pd.DataFrame([y_train.iloc[-1]] * test_size, columns=y_train.columns)\n",
    "mean_squared_error(df_naive, y_test)\n",
    "# df_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.808254</td>\n",
       "      <td>4.722639</td>\n",
       "      <td>4.730283</td>\n",
       "      <td>4.386444</td>\n",
       "      <td>4.244575</td>\n",
       "      <td>4.121847</td>\n",
       "      <td>4.052503</td>\n",
       "      <td>4.054090</td>\n",
       "      <td>4.125195</td>\n",
       "      <td>4.168106</td>\n",
       "      <td>4.521195</td>\n",
       "      <td>4.460731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.425504</td>\n",
       "      <td>7.759623</td>\n",
       "      <td>7.564955</td>\n",
       "      <td>6.729259</td>\n",
       "      <td>7.209680</td>\n",
       "      <td>6.702704</td>\n",
       "      <td>6.475952</td>\n",
       "      <td>6.409134</td>\n",
       "      <td>5.845021</td>\n",
       "      <td>6.518092</td>\n",
       "      <td>7.001816</td>\n",
       "      <td>6.102906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.688330</td>\n",
       "      <td>12.754750</td>\n",
       "      <td>11.603767</td>\n",
       "      <td>11.206963</td>\n",
       "      <td>11.773730</td>\n",
       "      <td>10.609055</td>\n",
       "      <td>9.988644</td>\n",
       "      <td>9.223608</td>\n",
       "      <td>7.769438</td>\n",
       "      <td>9.584902</td>\n",
       "      <td>10.734335</td>\n",
       "      <td>9.246078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.595896</td>\n",
       "      <td>20.126341</td>\n",
       "      <td>18.872407</td>\n",
       "      <td>18.177391</td>\n",
       "      <td>19.066755</td>\n",
       "      <td>17.503062</td>\n",
       "      <td>15.908176</td>\n",
       "      <td>14.377980</td>\n",
       "      <td>12.521150</td>\n",
       "      <td>15.198067</td>\n",
       "      <td>16.661805</td>\n",
       "      <td>14.342094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.693696</td>\n",
       "      <td>32.786344</td>\n",
       "      <td>30.992696</td>\n",
       "      <td>29.877886</td>\n",
       "      <td>31.374907</td>\n",
       "      <td>28.604893</td>\n",
       "      <td>25.897076</td>\n",
       "      <td>22.886119</td>\n",
       "      <td>20.458540</td>\n",
       "      <td>24.664812</td>\n",
       "      <td>26.611204</td>\n",
       "      <td>23.094519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5   \\\n",
       "0   4.808254   4.722639   4.730283   4.386444   4.244575   4.121847   \n",
       "1   7.425504   7.759623   7.564955   6.729259   7.209680   6.702704   \n",
       "2  12.688330  12.754750  11.603767  11.206963  11.773730  10.609055   \n",
       "3  20.595896  20.126341  18.872407  18.177391  19.066755  17.503062   \n",
       "4  33.693696  32.786344  30.992696  29.877886  31.374907  28.604893   \n",
       "\n",
       "          6          7          8          9          10         11  \n",
       "0   4.052503   4.054090   4.125195   4.168106   4.521195   4.460731  \n",
       "1   6.475952   6.409134   5.845021   6.518092   7.001816   6.102906  \n",
       "2   9.988644   9.223608   7.769438   9.584902  10.734335   9.246078  \n",
       "3  15.908176  14.377980  12.521150  15.198067  16.661805  14.342094  \n",
       "4  25.897076  22.886119  20.458540  24.664812  26.611204  23.094519  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-09</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-10</th>\n",
       "      <td>4.98</td>\n",
       "      <td>4.84</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.91</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-11</th>\n",
       "      <td>4.97</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-15</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-16</th>\n",
       "      <td>4.91</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.84</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-17</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18</th>\n",
       "      <td>4.92</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.97</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-21</th>\n",
       "      <td>4.92</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>4.89</td>\n",
       "      <td>4.81</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>4.88</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_1   y_2   y_3   y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  \\\n",
       "Date                                                                           \n",
       "2024-10-09  4.93  4.84  4.75  4.46  4.24  3.99  3.89  3.91  3.97  4.06  4.41   \n",
       "2024-10-10  4.98  4.84  4.75  4.45  4.22  3.98  3.88  3.91  3.99  4.09  4.44   \n",
       "2024-10-11  4.97  4.82  4.73  4.44  4.18  3.95  3.85  3.88  3.97  4.08  4.44   \n",
       "2024-10-15  4.93  4.82  4.73  4.42  4.18  3.95  3.86  3.86  3.93  4.03  4.37   \n",
       "2024-10-16  4.91  4.80  4.72  4.42  4.17  3.93  3.84  3.84  3.92  4.02  4.36   \n",
       "2024-10-17  4.93  4.83  4.74  4.45  4.21  3.96  3.89  3.90  3.99  4.09  4.44   \n",
       "2024-10-18  4.92  4.82  4.73  4.45  4.19  3.95  3.86  3.88  3.97  4.08  4.44   \n",
       "2024-10-21  4.92  4.82  4.73  4.47  4.24  4.02  3.95  3.98  4.07  4.19  4.54   \n",
       "2024-10-22  4.89  4.81  4.72  4.47  4.24  4.03  3.98  4.00  4.10  4.20  4.55   \n",
       "2024-10-23  4.88  4.80  4.73  4.48  4.27  4.07  4.03  4.05  4.14  4.24  4.58   \n",
       "\n",
       "            y_12  \n",
       "Date              \n",
       "2024-10-09  4.34  \n",
       "2024-10-10  4.38  \n",
       "2024-10-11  4.39  \n",
       "2024-10-15  4.32  \n",
       "2024-10-16  4.30  \n",
       "2024-10-17  4.39  \n",
       "2024-10-18  4.38  \n",
       "2024-10-21  4.49  \n",
       "2024-10-22  4.49  \n",
       "2024-10-23  4.51  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_1</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-08</th>\n",
       "      <td>4.96</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.21</td>\n",
       "      <td>3.98</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y_1   y_2   y_3   y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  \\\n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "2024-10-08  4.96  4.85  4.75  4.44  4.21  3.98  3.86  3.86  3.94  4.04  4.38   \n",
       "\n",
       "            y_12  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  \n",
       "2024-10-08  4.32  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module kan.MultKAN:\n",
      "\n",
      "fit(dataset, opt='LBFGS', steps=100, log=1, lamb=0.0, lamb_l1=1.0, lamb_entropy=2.0, lamb_coef=0.0, lamb_coefdiff=0.0, update_grid=True, grid_update_num=10, loss_fn=None, lr=1.0, start_grid_update_step=-1, stop_grid_update_step=50, batch=-1, metrics=None, save_fig=False, in_vars=None, out_vars=None, beta=3, save_fig_freq=1, img_folder='./video', singularity_avoiding=False, y_th=1000.0, reg_metric='edge_forward_spline_n', display_metrics=None) method of kan.MultKAN.MultKAN instance\n",
      "    training\n",
      "\n",
      "    Args:\n",
      "    -----\n",
      "        dataset : dic\n",
      "            contains dataset['train_input'], dataset['train_label'], dataset['test_input'], dataset['test_label']\n",
      "        opt : str\n",
      "            \"LBFGS\" or \"Adam\"\n",
      "        steps : int\n",
      "            training steps\n",
      "        log : int\n",
      "            logging frequency\n",
      "        lamb : float\n",
      "            overall penalty strength\n",
      "        lamb_l1 : float\n",
      "            l1 penalty strength\n",
      "        lamb_entropy : float\n",
      "            entropy penalty strength\n",
      "        lamb_coef : float\n",
      "            coefficient magnitude penalty strength\n",
      "        lamb_coefdiff : float\n",
      "            difference of nearby coefficits (smoothness) penalty strength\n",
      "        update_grid : bool\n",
      "            If True, update grid regularly before stop_grid_update_step\n",
      "        grid_update_num : int\n",
      "            the number of grid updates before stop_grid_update_step\n",
      "        start_grid_update_step : int\n",
      "            no grid updates before this training step\n",
      "        stop_grid_update_step : int\n",
      "            no grid updates after this training step\n",
      "        loss_fn : function\n",
      "            loss function\n",
      "        lr : float\n",
      "            learning rate\n",
      "        batch : int\n",
      "            batch size, if -1 then full.\n",
      "        save_fig_freq : int\n",
      "            save figure every (save_fig_freq) steps\n",
      "        singularity_avoiding : bool\n",
      "            indicate whether to avoid singularity for the symbolic part\n",
      "        y_th : float\n",
      "            singularity threshold (anything above the threshold is considered singular and is softened in some ways)\n",
      "        reg_metric : str\n",
      "            regularization metric. Choose from {'edge_forward_spline_n', 'edge_forward_spline_u', 'edge_forward_sum', 'edge_backward', 'node_backward'}\n",
      "        metrics : a list of metrics (as functions)\n",
      "            the metrics to be computed in training\n",
      "        display_metrics : a list of functions\n",
      "            the metric to be displayed in tqdm progress bar\n",
      "\n",
      "    Returns:\n",
      "    --------\n",
      "        results : dic\n",
      "            results['train_loss'], 1D array of training losses (RMSE)\n",
      "            results['test_loss'], 1D array of test losses (RMSE)\n",
      "            results['reg'], 1D array of regularization\n",
      "            other metrics specified in metrics\n",
      "\n",
      "    Example\n",
      "    -------\n",
      "    >>> from kan import *\n",
      "    >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.3, seed=2)\n",
      "    >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
      "    >>> dataset = create_dataset(f, n_var=2)\n",
      "    >>> model.fit(dataset, opt='LBFGS', steps=20, lamb=0.001);\n",
      "    >>> model.plot()\n",
      "    # Most examples in toturals involve the fit() method. Please check them for useness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
