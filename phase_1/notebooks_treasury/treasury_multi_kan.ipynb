{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from kan import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>y_10</th>\n",
       "      <th>y_11</th>\n",
       "      <th>y_12</th>\n",
       "      <th>y_13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-26</th>\n",
       "      <td>4.76</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.21</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-27</th>\n",
       "      <td>4.76</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-29</th>\n",
       "      <td>4.75</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.13</td>\n",
       "      <td>...</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.18</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>4.66</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>4.65</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9  ...  \\\n",
       "Date                                                                    ...   \n",
       "2024-11-26  4.76  4.70  4.60  4.54  4.43  4.34  4.19  4.17  4.11  4.17  ...   \n",
       "2024-11-27  4.76  4.69  4.58  4.52  4.42  4.30  4.13  4.10  4.05  4.10  ...   \n",
       "2024-11-29  4.75  4.63  4.51  4.51  4.43  4.30  4.17  4.11  4.08  4.13  ...   \n",
       "2024-12-02  4.66  4.56  4.49  4.48  4.40  4.27  4.17  4.13  4.11  4.17  ...   \n",
       "2024-12-03  4.65  4.54  4.47  4.46  4.38  4.23  4.13  4.09  4.07  4.13  ...   \n",
       "\n",
       "             y_4   y_5   y_6   y_7   y_8   y_9  y_10  y_11  y_12  y_13  \n",
       "Date                                                                    \n",
       "2024-11-26  4.52  4.45  4.37  4.21  4.21  4.17  4.24  4.30  4.56  4.48  \n",
       "2024-11-27  4.54  4.43  4.34  4.19  4.17  4.11  4.17  4.25  4.52  4.44  \n",
       "2024-11-29  4.52  4.42  4.30  4.13  4.10  4.05  4.10  4.18  4.45  4.36  \n",
       "2024-12-02  4.51  4.43  4.30  4.17  4.11  4.08  4.13  4.19  4.46  4.36  \n",
       "2024-12-03  4.48  4.40  4.27  4.17  4.13  4.11  4.17  4.23  4.50  4.40  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def treasury_data_retrieval():\n",
    "    df = pd.read_csv('../data/us_treasury_rates.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values(by='Date', ascending=True, inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = treasury_data_retrieval()\n",
    "\n",
    "n = len(df)\n",
    "h = 3\n",
    "\n",
    "flatten = pd.DataFrame()\n",
    "for id in range(1, n):\n",
    "    row = df.iloc[id:(id+h), 1:].stack().reset_index(drop=True).to_frame().T\n",
    "    flatten = pd.concat([flatten, row], ignore_index=True)\n",
    "\n",
    "for id in range(1, 14):\n",
    "    flatten[f'y_{id}'] = df.iloc[:(n-1), id]\n",
    "\n",
    "flatten['Date'] = df['Date']\n",
    "flatten.dropna(inplace=True)\n",
    "flatten.columns = flatten.columns.astype(str)\n",
    "flatten.set_index('Date', inplace=True)\n",
    "\n",
    "flatten.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mse():\n",
    "    predictions = model(dataset['train_input']).squeeze()  # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['train_label'], reduction='mean')  # Compute MSE\n",
    "    return mse  # Return scalar MSE value\n",
    "\n",
    "def test_mse():\n",
    "    predictions = model(dataset['test_input']).squeeze()  # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['test_label'], reduction='mean')  # Compute MSE\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliding Window Iteration: Train[0:380] Test[380:410]\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.14e-01 | test_loss: 6.36e-02 | reg: 9.59e+01 | : 100%|â–ˆ| 500/500 [00:12<00:00, 40.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Sliding Window Iteration: Train[30:410] Test[410:440]\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.12e-01 | test_loss: 6.56e-02 | reg: 9.25e+01 | : 100%|â–ˆ| 500/500 [00:12<00:00, 41.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Sliding Window Iteration: Train[60:440] Test[440:470]\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.09e-01 | test_loss: 1.82e-01 | reg: 9.17e+01 | : 100%|â–ˆ| 500/500 [00:11<00:00, 42.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Sliding Window Iteration: Train[90:470] Test[470:500]\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.04e-01 | test_loss: 2.20e-01 | reg: 9.04e+01 | : 100%|â–ˆ| 500/500 [00:11<00:00, 42.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Sliding Window Iteration: Train[120:500] Test[500:530]\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 8.69e-02 | test_loss: 2.05e-01 | reg: 9.03e+01 | : 100%|â–ˆ| 500/500 [00:11<00:00, 42.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Sliding Window Cross-Validation Results\n",
      "Average Train MSE: 0.011100981627021769\n",
      "Average Test MSE: 0.026332114270081773\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters for the sliding window\n",
    "window_size = 380  # Number of samples in the training window\n",
    "test_size = 30     # Number of samples in the test set for each iteration\n",
    "\n",
    "# Store results for each fold\n",
    "fold_results = {'train_mse': [], 'test_mse': []}\n",
    "\n",
    "# Prepare data\n",
    "X, y = flatten.iloc[:, :-13], flatten.iloc[:, -13:]\n",
    "n_inputs = X.shape[1]\n",
    "n_outputs = y.shape[1]\n",
    "\n",
    "# Sliding window cross-validation\n",
    "for start in range(0, len(X) + 1 - window_size - test_size, test_size):\n",
    "    # Define the train and test indices\n",
    "    train_idx = range(start, start + window_size)\n",
    "    test_idx = range(start + window_size, start + window_size + test_size)\n",
    "    \n",
    "    print(f\"Sliding Window Iteration: Train[{start}:{start+window_size}] Test[{start+window_size}:{start+window_size+test_size}]\")\n",
    "    \n",
    "    # Split data into train and test for the current window\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Prepare dataset for the current window\n",
    "    dataset = dict()\n",
    "    dtype = torch.get_default_dtype()\n",
    "    dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "    dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "    dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype).to(device)\n",
    "    dataset['test_label'] = torch.from_numpy(y_test.values).type(dtype).to(device)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = KAN(width=[n_inputs, 20, n_outputs], grid=3, k=2, seed=42, device=device)\n",
    "    \n",
    "    # Train the model and compute metrics\n",
    "    results = model.fit(dataset, opt=\"Adam\", lamb=0.0, lr=0.001, steps=500, metrics=(train_mse, test_mse))\n",
    "\n",
    "    # Store the metrics\n",
    "    fold_results['train_mse'].append(results['train_mse'][-1])\n",
    "    fold_results['test_mse'].append(results['test_mse'][-1])\n",
    "\n",
    "# Calculate average metrics across all windows\n",
    "avg_train_mse = np.mean(fold_results['train_mse'])\n",
    "avg_test_mse = np.mean(fold_results['test_mse'])\n",
    "\n",
    "print(\"Sliding Window Cross-Validation Results\")\n",
    "print(f\"Average Train MSE: {avg_train_mse}\")\n",
    "print(f\"Average Test MSE: {avg_test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04191239915109833)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "y_pred = model(dataset['test_input']).cpu().detach().numpy().flatten()\n",
    "y_test = dataset['test_label'].cpu().detach().numpy().flatten()\n",
    "\n",
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.760041</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.947244</td>\n",
       "      <td>4.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.920877</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.871707</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.548059</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred  real\n",
       "0  4.760041  4.92\n",
       "1  4.947244  4.82\n",
       "2  4.920877  4.73\n",
       "3  4.871707  4.65\n",
       "4  4.548059  4.45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'pred': y_pred,\n",
    "    'real': y_test}).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module kan.MultKAN:\n",
      "\n",
      "fit(dataset, opt='LBFGS', steps=100, log=1, lamb=0.0, lamb_l1=1.0, lamb_entropy=2.0, lamb_coef=0.0, lamb_coefdiff=0.0, update_grid=True, grid_update_num=10, loss_fn=None, lr=1.0, start_grid_update_step=-1, stop_grid_update_step=50, batch=-1, metrics=None, save_fig=False, in_vars=None, out_vars=None, beta=3, save_fig_freq=1, img_folder='./video', singularity_avoiding=False, y_th=1000.0, reg_metric='edge_forward_spline_n', display_metrics=None) method of kan.MultKAN.MultKAN instance\n",
      "    training\n",
      "\n",
      "    Args:\n",
      "    -----\n",
      "        dataset : dic\n",
      "            contains dataset['train_input'], dataset['train_label'], dataset['test_input'], dataset['test_label']\n",
      "        opt : str\n",
      "            \"LBFGS\" or \"Adam\"\n",
      "        steps : int\n",
      "            training steps\n",
      "        log : int\n",
      "            logging frequency\n",
      "        lamb : float\n",
      "            overall penalty strength\n",
      "        lamb_l1 : float\n",
      "            l1 penalty strength\n",
      "        lamb_entropy : float\n",
      "            entropy penalty strength\n",
      "        lamb_coef : float\n",
      "            coefficient magnitude penalty strength\n",
      "        lamb_coefdiff : float\n",
      "            difference of nearby coefficits (smoothness) penalty strength\n",
      "        update_grid : bool\n",
      "            If True, update grid regularly before stop_grid_update_step\n",
      "        grid_update_num : int\n",
      "            the number of grid updates before stop_grid_update_step\n",
      "        start_grid_update_step : int\n",
      "            no grid updates before this training step\n",
      "        stop_grid_update_step : int\n",
      "            no grid updates after this training step\n",
      "        loss_fn : function\n",
      "            loss function\n",
      "        lr : float\n",
      "            learning rate\n",
      "        batch : int\n",
      "            batch size, if -1 then full.\n",
      "        save_fig_freq : int\n",
      "            save figure every (save_fig_freq) steps\n",
      "        singularity_avoiding : bool\n",
      "            indicate whether to avoid singularity for the symbolic part\n",
      "        y_th : float\n",
      "            singularity threshold (anything above the threshold is considered singular and is softened in some ways)\n",
      "        reg_metric : str\n",
      "            regularization metric. Choose from {'edge_forward_spline_n', 'edge_forward_spline_u', 'edge_forward_sum', 'edge_backward', 'node_backward'}\n",
      "        metrics : a list of metrics (as functions)\n",
      "            the metrics to be computed in training\n",
      "        display_metrics : a list of functions\n",
      "            the metric to be displayed in tqdm progress bar\n",
      "\n",
      "    Returns:\n",
      "    --------\n",
      "        results : dic\n",
      "            results['train_loss'], 1D array of training losses (RMSE)\n",
      "            results['test_loss'], 1D array of test losses (RMSE)\n",
      "            results['reg'], 1D array of regularization\n",
      "            other metrics specified in metrics\n",
      "\n",
      "    Example\n",
      "    -------\n",
      "    >>> from kan import *\n",
      "    >>> model = KAN(width=[2,5,1], grid=5, k=3, noise_scale=0.3, seed=2)\n",
      "    >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
      "    >>> dataset = create_dataset(f, n_var=2)\n",
      "    >>> model.fit(dataset, opt='LBFGS', steps=20, lamb=0.001);\n",
      "    >>> model.plot()\n",
      "    # Most examples in toturals involve the fit() method. Please check them for useness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
