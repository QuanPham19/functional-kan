{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from kan import *\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from treasury_base import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_pred_retrieval():\n",
    "    data = treasury_data_retrieval('us_treasury_rates_large.csv')\n",
    "    data = data.set_index('Date')\n",
    "    targets = data.columns\n",
    "\n",
    "    # List of moving average windows\n",
    "    window_list = [1, 3, 5]\n",
    "\n",
    "    # List of lags to calculate moving average\n",
    "    lag_list = [1]\n",
    "\n",
    "    # List of future date values\n",
    "    shift_list = [_ for _ in range(20)]\n",
    "\n",
    "    # Generate future columns\n",
    "    for shift in shift_list:\n",
    "        for col in targets:\n",
    "            data[f'{col}_+_{shift}'] = data[col].shift(-shift)\n",
    "\n",
    "    # Generate past moving average columns\n",
    "    for lag in lag_list:\n",
    "        for window in window_list:\n",
    "            for col in targets:\n",
    "                data[f'{col}_-_{lag}_window_{window}'] = data[col].shift(1).rolling(window).mean()\n",
    "    return data, targets\n",
    "\n",
    "def train_mse():\n",
    "    predictions = model(dataset['train_input'])  # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['train_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5  # Return scalar MSE value\n",
    "\n",
    "def test_mse():\n",
    "    predictions = model(dataset['test_input']) # Model predictions\n",
    "    mse = F.mse_loss(predictions, dataset['test_label'], reduction='mean')  # Compute MSE\n",
    "    return mse ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Mo</th>\n",
       "      <th>2 Mo</th>\n",
       "      <th>3 Mo</th>\n",
       "      <th>6 Mo</th>\n",
       "      <th>1 Yr</th>\n",
       "      <th>2 Yr</th>\n",
       "      <th>3 Yr</th>\n",
       "      <th>5 Yr</th>\n",
       "      <th>7 Yr</th>\n",
       "      <th>10 Yr</th>\n",
       "      <th>...</th>\n",
       "      <th>3 Mo_-_1_window_5</th>\n",
       "      <th>6 Mo_-_1_window_5</th>\n",
       "      <th>1 Yr_-_1_window_5</th>\n",
       "      <th>2 Yr_-_1_window_5</th>\n",
       "      <th>3 Yr_-_1_window_5</th>\n",
       "      <th>5 Yr_-_1_window_5</th>\n",
       "      <th>7 Yr_-_1_window_5</th>\n",
       "      <th>10 Yr_-_1_window_5</th>\n",
       "      <th>20 Yr_-_1_window_5</th>\n",
       "      <th>30 Yr_-_1_window_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>4.75</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>...</td>\n",
       "      <td>4.608</td>\n",
       "      <td>4.444</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.222</td>\n",
       "      <td>4.202</td>\n",
       "      <td>4.160</td>\n",
       "      <td>4.214</td>\n",
       "      <td>4.282</td>\n",
       "      <td>4.546</td>\n",
       "      <td>4.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>4.66</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.23</td>\n",
       "      <td>...</td>\n",
       "      <td>4.584</td>\n",
       "      <td>4.438</td>\n",
       "      <td>4.336</td>\n",
       "      <td>4.182</td>\n",
       "      <td>4.160</td>\n",
       "      <td>4.116</td>\n",
       "      <td>4.170</td>\n",
       "      <td>4.238</td>\n",
       "      <td>4.504</td>\n",
       "      <td>4.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-04</th>\n",
       "      <td>4.65</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>...</td>\n",
       "      <td>4.558</td>\n",
       "      <td>4.426</td>\n",
       "      <td>4.316</td>\n",
       "      <td>4.174</td>\n",
       "      <td>4.144</td>\n",
       "      <td>4.104</td>\n",
       "      <td>4.162</td>\n",
       "      <td>4.230</td>\n",
       "      <td>4.498</td>\n",
       "      <td>4.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-05</th>\n",
       "      <td>4.59</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.530</td>\n",
       "      <td>4.412</td>\n",
       "      <td>4.288</td>\n",
       "      <td>4.158</td>\n",
       "      <td>4.120</td>\n",
       "      <td>4.084</td>\n",
       "      <td>4.140</td>\n",
       "      <td>4.208</td>\n",
       "      <td>4.476</td>\n",
       "      <td>4.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-06</th>\n",
       "      <td>4.57</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.502</td>\n",
       "      <td>4.402</td>\n",
       "      <td>4.266</td>\n",
       "      <td>4.150</td>\n",
       "      <td>4.106</td>\n",
       "      <td>4.076</td>\n",
       "      <td>4.130</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.458</td>\n",
       "      <td>4.360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1 Mo  2 Mo  3 Mo  6 Mo  1 Yr  2 Yr  3 Yr  5 Yr  7 Yr  10 Yr  ...  \\\n",
       "Date                                                                     ...   \n",
       "2024-12-02  4.75  4.63  4.51  4.43  4.30  4.17  4.11  4.08  4.13   4.19  ...   \n",
       "2024-12-03  4.66  4.56  4.49  4.40  4.27  4.17  4.13  4.11  4.17   4.23  ...   \n",
       "2024-12-04  4.65  4.54  4.47  4.38  4.23  4.13  4.09  4.07  4.13   4.19  ...   \n",
       "2024-12-05  4.59  4.53  4.46  4.38  4.23  4.15  4.10  4.07  4.12   4.17  ...   \n",
       "2024-12-06  4.57  4.50  4.42  4.34  4.19  4.10  4.05  4.03  4.09   4.15  ...   \n",
       "\n",
       "            3 Mo_-_1_window_5  6 Mo_-_1_window_5  1 Yr_-_1_window_5  \\\n",
       "Date                                                                  \n",
       "2024-12-02              4.608              4.444              4.360   \n",
       "2024-12-03              4.584              4.438              4.336   \n",
       "2024-12-04              4.558              4.426              4.316   \n",
       "2024-12-05              4.530              4.412              4.288   \n",
       "2024-12-06              4.502              4.402              4.266   \n",
       "\n",
       "            2 Yr_-_1_window_5  3 Yr_-_1_window_5  5 Yr_-_1_window_5  \\\n",
       "Date                                                                  \n",
       "2024-12-02              4.222              4.202              4.160   \n",
       "2024-12-03              4.182              4.160              4.116   \n",
       "2024-12-04              4.174              4.144              4.104   \n",
       "2024-12-05              4.158              4.120              4.084   \n",
       "2024-12-06              4.150              4.106              4.076   \n",
       "\n",
       "            7 Yr_-_1_window_5  10 Yr_-_1_window_5  20 Yr_-_1_window_5  \\\n",
       "Date                                                                    \n",
       "2024-12-02              4.214               4.282               4.546   \n",
       "2024-12-03              4.170               4.238               4.504   \n",
       "2024-12-04              4.162               4.230               4.498   \n",
       "2024-12-05              4.140               4.208               4.476   \n",
       "2024-12-06              4.130               4.192               4.458   \n",
       "\n",
       "            30 Yr_-_1_window_5  \n",
       "Date                            \n",
       "2024-12-02               4.466  \n",
       "2024-12-03               4.418  \n",
       "2024-12-04               4.408  \n",
       "2024-12-05               4.382  \n",
       "2024-12-06               4.360  \n",
       "\n",
       "[5 rows x 288 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, ori_col = direct_pred_retrieval()\n",
    "all_cols = data.columns\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -15, FUTURE STEPS: 1\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 8.35e-02 | test_loss: 3.40e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 31.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -15, FUTURE STEPS: 2\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.00e-01 | test_loss: 3.57e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 31.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -15, FUTURE STEPS: 3\n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.13e-01 | test_loss: 3.65e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:15<00:00, 31.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -15, FUTURE STEPS: 4\n",
      "497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.23e-01 | test_loss: 3.62e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:15<00:00, 31.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -15, FUTURE STEPS: 5\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.32e-01 | test_loss: 3.78e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -10, FUTURE STEPS: 1\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 8.28e-02 | test_loss: 3.08e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -10, FUTURE STEPS: 2\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 9.95e-02 | test_loss: 3.13e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -10, FUTURE STEPS: 3\n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.12e-01 | test_loss: 2.95e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -10, FUTURE STEPS: 4\n",
      "497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.22e-01 | test_loss: 3.09e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -10, FUTURE STEPS: 5\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.31e-01 | test_loss: 3.50e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -5, FUTURE STEPS: 1\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 8.23e-02 | test_loss: 3.20e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -5, FUTURE STEPS: 2\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 9.91e-02 | test_loss: 3.43e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -5, FUTURE STEPS: 3\n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.12e-01 | test_loss: 3.44e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -5, FUTURE STEPS: 4\n",
      "497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.22e-01 | test_loss: 3.65e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: -5, FUTURE STEPS: 5\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.31e-01 | test_loss: 3.71e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: 0, FUTURE STEPS: 1\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 8.24e-02 | test_loss: 4.33e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: 0, FUTURE STEPS: 2\n",
      "499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 9.90e-02 | test_loss: 3.56e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: 0, FUTURE STEPS: 3\n",
      "498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.11e-01 | test_loss: 3.47e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: 0, FUTURE STEPS: 4\n",
      "497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.22e-01 | test_loss: 3.00e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAST DAY OF DATASET: 0, FUTURE STEPS: 5\n",
      "496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 1.31e-01 | test_loss: 2.85e-01 | reg: 0.00e+00 | : 100%|█| 500/500 [00:16<00:00, 30.52\n"
     ]
    }
   ],
   "source": [
    "# Out-of-sample test size, diff between sliding element = test size\n",
    "test_size = 5\n",
    "sliding_list = [15, 10, 5, 0]\n",
    "\n",
    "# Set variables for cross-validation\n",
    "truth_df = pd.DataFrame()\n",
    "naive_df = pd.DataFrame()\n",
    "kan_df = pd.DataFrame()\n",
    "\n",
    "# Loop over sliding windows\n",
    "for sliding in sliding_list:\n",
    "    \n",
    "    # Trim original data by sliding window size\n",
    "    df = data[:len(data)-sliding]\n",
    "\n",
    "    # Use 2 years of data (500 days) for training\n",
    "    df_train, df_test = df[-test_size-500:-test_size], df[-test_size:]\n",
    "    len_train = len(df_train)\n",
    "\n",
    "    # Append to truth dataframe\n",
    "    truth_df = pd.concat([truth_df, df_test[ori_col]], axis=0, ignore_index=False)\n",
    "\n",
    "    # Append to naive dataframe\n",
    "    naive_element = pd.DataFrame([df_train[ori_col].iloc[-1].values] * test_size)\n",
    "    naive_df = pd.concat([naive_df, naive_element], axis=0, ignore_index=True)\n",
    "\n",
    "    # Initialize predictions array\n",
    "    pred = list()\n",
    "\n",
    "    for h in range(test_size):\n",
    "\n",
    "        # Print checkpoints\n",
    "        print(f'LAST DAY OF DATASET: {-sliding}, FUTURE STEPS: {h+1}')\n",
    "\n",
    "        # If h = 0 target columns unchanged\n",
    "        if h == 0:  \n",
    "            target_col = ori_col\n",
    "        # If h > 0 target columns modified\n",
    "        else:       \n",
    "            target_col = [f'{element}_+_{h}' for element in ori_col]\n",
    "        \n",
    "        # Extract feature columns\n",
    "        feature_col = [element for element in all_cols if 'window' in element]\n",
    "\n",
    "        # Cut train data due to direct forecast\n",
    "        df_train_modified = df_train[:(len_train-h)]\n",
    "\n",
    "        # Test data is the first row \n",
    "        df_test_modified = df_test.iloc[[0]]\n",
    "        print(len(df_train_modified))\n",
    "\n",
    "        X_train, y_train = df_train_modified[feature_col], df_train_modified[target_col]\n",
    "        X_test, y_test = df_test_modified[feature_col], df_test.iloc[h][ori_col]\n",
    "\n",
    "        n_inputs = X_train.shape[1]\n",
    "        n_outputs = y_train.shape[1]\n",
    "\n",
    "        dataset = dict()\n",
    "        dtype = torch.get_default_dtype()\n",
    "        dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "        dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "        dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype).to(device)\n",
    "        dataset['test_label'] = torch.from_numpy(y_test.values).type(dtype).to(device)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = KAN(width=[n_inputs, 32, n_outputs], grid=3, k=2, seed=42, device=device, symbolic_enabled=False, save_act=False, auto_save=False)\n",
    "\n",
    "        # Train the model and compute metrics\n",
    "        results = model.fit(dataset, opt=\"Adam\", lr=0.001, steps=500, metrics=(train_mse, test_mse))\n",
    "\n",
    "        # loss_fn = loss_fn_eval = lambda x, y: torch.mean((x - y) ** 2)\n",
    "        # p = \n",
    "        # train_loss = loss_fn(p, dataset['train_label'])\n",
    "        # print(train_loss)\n",
    "        # torch.sqrt(train_loss).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        pred.append(model.forward(dataset['test_input']).cpu().detach().numpy().flatten())\n",
    "        # print(n_inputs, n_outputs)\n",
    "\n",
    "    kan_element = pd.DataFrame(pred)\n",
    "    kan_df = pd.concat([kan_element, kan_df], axis=0, ignore_index=True)\n",
    "\n",
    "# df_train_modified\n",
    "# df_test_modified\n",
    "# y_train\n",
    "# X_test\n",
    "# model(dataset['test_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames have been saved to dfs_5_steps_ahead.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "dataframes = {\n",
    "    \"naive_df\": naive_df,\n",
    "    \"kan_df\": kan_df,\n",
    "    \"truth_df\": truth_df\n",
    "}\n",
    "\n",
    "# Specify the file name\n",
    "filename = f\"dfs_{test_size}_steps_ahead.pkl\"\n",
    "\n",
    "# Pickle the DataFrames into a file\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(dataframes, file)\n",
    "\n",
    "print(f\"DataFrames have been saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.664077</td>\n",
       "      <td>4.688048</td>\n",
       "      <td>4.587062</td>\n",
       "      <td>4.494512</td>\n",
       "      <td>4.260644</td>\n",
       "      <td>4.201187</td>\n",
       "      <td>4.101785</td>\n",
       "      <td>4.087987</td>\n",
       "      <td>4.173543</td>\n",
       "      <td>4.257468</td>\n",
       "      <td>4.514432</td>\n",
       "      <td>4.414955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.657927</td>\n",
       "      <td>4.686383</td>\n",
       "      <td>4.583114</td>\n",
       "      <td>4.494854</td>\n",
       "      <td>4.256866</td>\n",
       "      <td>4.207688</td>\n",
       "      <td>4.103733</td>\n",
       "      <td>4.087243</td>\n",
       "      <td>4.171134</td>\n",
       "      <td>4.257544</td>\n",
       "      <td>4.509745</td>\n",
       "      <td>4.412368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.655965</td>\n",
       "      <td>4.684406</td>\n",
       "      <td>4.582168</td>\n",
       "      <td>4.495437</td>\n",
       "      <td>4.254067</td>\n",
       "      <td>4.214918</td>\n",
       "      <td>4.107992</td>\n",
       "      <td>4.088882</td>\n",
       "      <td>4.172706</td>\n",
       "      <td>4.260308</td>\n",
       "      <td>4.508608</td>\n",
       "      <td>4.411867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.653932</td>\n",
       "      <td>4.680718</td>\n",
       "      <td>4.580797</td>\n",
       "      <td>4.493187</td>\n",
       "      <td>4.246843</td>\n",
       "      <td>4.218612</td>\n",
       "      <td>4.108695</td>\n",
       "      <td>4.086651</td>\n",
       "      <td>4.172275</td>\n",
       "      <td>4.261654</td>\n",
       "      <td>4.508310</td>\n",
       "      <td>4.411677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.651916</td>\n",
       "      <td>4.677289</td>\n",
       "      <td>4.579257</td>\n",
       "      <td>4.492207</td>\n",
       "      <td>4.240483</td>\n",
       "      <td>4.222777</td>\n",
       "      <td>4.112291</td>\n",
       "      <td>4.085840</td>\n",
       "      <td>4.174062</td>\n",
       "      <td>4.264005</td>\n",
       "      <td>4.510499</td>\n",
       "      <td>4.413914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.680726</td>\n",
       "      <td>4.726865</td>\n",
       "      <td>4.644698</td>\n",
       "      <td>4.557314</td>\n",
       "      <td>4.259408</td>\n",
       "      <td>4.301532</td>\n",
       "      <td>4.232587</td>\n",
       "      <td>4.199530</td>\n",
       "      <td>4.292241</td>\n",
       "      <td>4.426102</td>\n",
       "      <td>4.671994</td>\n",
       "      <td>4.553437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.674823</td>\n",
       "      <td>4.722688</td>\n",
       "      <td>4.642234</td>\n",
       "      <td>4.562012</td>\n",
       "      <td>4.249754</td>\n",
       "      <td>4.304034</td>\n",
       "      <td>4.228899</td>\n",
       "      <td>4.187629</td>\n",
       "      <td>4.278012</td>\n",
       "      <td>4.414305</td>\n",
       "      <td>4.658885</td>\n",
       "      <td>4.542194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.670188</td>\n",
       "      <td>4.719267</td>\n",
       "      <td>4.640413</td>\n",
       "      <td>4.569526</td>\n",
       "      <td>4.252605</td>\n",
       "      <td>4.313445</td>\n",
       "      <td>4.229526</td>\n",
       "      <td>4.181122</td>\n",
       "      <td>4.265705</td>\n",
       "      <td>4.409812</td>\n",
       "      <td>4.651341</td>\n",
       "      <td>4.528942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.668747</td>\n",
       "      <td>4.715051</td>\n",
       "      <td>4.639814</td>\n",
       "      <td>4.576725</td>\n",
       "      <td>4.250079</td>\n",
       "      <td>4.319502</td>\n",
       "      <td>4.229107</td>\n",
       "      <td>4.170929</td>\n",
       "      <td>4.251718</td>\n",
       "      <td>4.403395</td>\n",
       "      <td>4.644707</td>\n",
       "      <td>4.517911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.665903</td>\n",
       "      <td>4.708537</td>\n",
       "      <td>4.638195</td>\n",
       "      <td>4.582404</td>\n",
       "      <td>4.238300</td>\n",
       "      <td>4.321162</td>\n",
       "      <td>4.228612</td>\n",
       "      <td>4.158962</td>\n",
       "      <td>4.238959</td>\n",
       "      <td>4.392817</td>\n",
       "      <td>4.636510</td>\n",
       "      <td>4.507975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.665979</td>\n",
       "      <td>4.741487</td>\n",
       "      <td>4.646986</td>\n",
       "      <td>4.559673</td>\n",
       "      <td>4.284008</td>\n",
       "      <td>4.312378</td>\n",
       "      <td>4.225003</td>\n",
       "      <td>4.177069</td>\n",
       "      <td>4.265076</td>\n",
       "      <td>4.421086</td>\n",
       "      <td>4.673464</td>\n",
       "      <td>4.540991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.663754</td>\n",
       "      <td>4.737903</td>\n",
       "      <td>4.642946</td>\n",
       "      <td>4.568484</td>\n",
       "      <td>4.281579</td>\n",
       "      <td>4.319957</td>\n",
       "      <td>4.224621</td>\n",
       "      <td>4.165707</td>\n",
       "      <td>4.249231</td>\n",
       "      <td>4.411282</td>\n",
       "      <td>4.660875</td>\n",
       "      <td>4.524203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.663619</td>\n",
       "      <td>4.739061</td>\n",
       "      <td>4.651961</td>\n",
       "      <td>4.586778</td>\n",
       "      <td>4.268772</td>\n",
       "      <td>4.324915</td>\n",
       "      <td>4.224811</td>\n",
       "      <td>4.157068</td>\n",
       "      <td>4.231308</td>\n",
       "      <td>4.398951</td>\n",
       "      <td>4.645172</td>\n",
       "      <td>4.506776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.665100</td>\n",
       "      <td>4.734181</td>\n",
       "      <td>4.648733</td>\n",
       "      <td>4.600241</td>\n",
       "      <td>4.271409</td>\n",
       "      <td>4.332584</td>\n",
       "      <td>4.221273</td>\n",
       "      <td>4.141382</td>\n",
       "      <td>4.209155</td>\n",
       "      <td>4.387005</td>\n",
       "      <td>4.633124</td>\n",
       "      <td>4.484800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.665383</td>\n",
       "      <td>4.725296</td>\n",
       "      <td>4.641176</td>\n",
       "      <td>4.608894</td>\n",
       "      <td>4.255402</td>\n",
       "      <td>4.333204</td>\n",
       "      <td>4.216415</td>\n",
       "      <td>4.124698</td>\n",
       "      <td>4.191792</td>\n",
       "      <td>4.372774</td>\n",
       "      <td>4.622047</td>\n",
       "      <td>4.468780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.709641</td>\n",
       "      <td>4.742804</td>\n",
       "      <td>4.658519</td>\n",
       "      <td>4.543219</td>\n",
       "      <td>4.253460</td>\n",
       "      <td>4.228101</td>\n",
       "      <td>4.157092</td>\n",
       "      <td>4.109575</td>\n",
       "      <td>4.220700</td>\n",
       "      <td>4.387587</td>\n",
       "      <td>4.643235</td>\n",
       "      <td>4.528277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.698521</td>\n",
       "      <td>4.739191</td>\n",
       "      <td>4.652665</td>\n",
       "      <td>4.548754</td>\n",
       "      <td>4.251203</td>\n",
       "      <td>4.230456</td>\n",
       "      <td>4.146784</td>\n",
       "      <td>4.093434</td>\n",
       "      <td>4.195589</td>\n",
       "      <td>4.368830</td>\n",
       "      <td>4.625434</td>\n",
       "      <td>4.505712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.696217</td>\n",
       "      <td>4.737129</td>\n",
       "      <td>4.648003</td>\n",
       "      <td>4.556075</td>\n",
       "      <td>4.248187</td>\n",
       "      <td>4.235888</td>\n",
       "      <td>4.138464</td>\n",
       "      <td>4.077472</td>\n",
       "      <td>4.172333</td>\n",
       "      <td>4.353811</td>\n",
       "      <td>4.608896</td>\n",
       "      <td>4.483943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.697104</td>\n",
       "      <td>4.735684</td>\n",
       "      <td>4.647111</td>\n",
       "      <td>4.570990</td>\n",
       "      <td>4.252269</td>\n",
       "      <td>4.246329</td>\n",
       "      <td>4.138485</td>\n",
       "      <td>4.066039</td>\n",
       "      <td>4.151629</td>\n",
       "      <td>4.341901</td>\n",
       "      <td>4.596337</td>\n",
       "      <td>4.463836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.698404</td>\n",
       "      <td>4.734125</td>\n",
       "      <td>4.643395</td>\n",
       "      <td>4.581351</td>\n",
       "      <td>4.249566</td>\n",
       "      <td>4.253631</td>\n",
       "      <td>4.133756</td>\n",
       "      <td>4.050708</td>\n",
       "      <td>4.127117</td>\n",
       "      <td>4.325795</td>\n",
       "      <td>4.580877</td>\n",
       "      <td>4.443470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   4.664077  4.688048  4.587062  4.494512  4.260644  4.201187  4.101785   \n",
       "1   4.657927  4.686383  4.583114  4.494854  4.256866  4.207688  4.103733   \n",
       "2   4.655965  4.684406  4.582168  4.495437  4.254067  4.214918  4.107992   \n",
       "3   4.653932  4.680718  4.580797  4.493187  4.246843  4.218612  4.108695   \n",
       "4   4.651916  4.677289  4.579257  4.492207  4.240483  4.222777  4.112291   \n",
       "5   4.680726  4.726865  4.644698  4.557314  4.259408  4.301532  4.232587   \n",
       "6   4.674823  4.722688  4.642234  4.562012  4.249754  4.304034  4.228899   \n",
       "7   4.670188  4.719267  4.640413  4.569526  4.252605  4.313445  4.229526   \n",
       "8   4.668747  4.715051  4.639814  4.576725  4.250079  4.319502  4.229107   \n",
       "9   4.665903  4.708537  4.638195  4.582404  4.238300  4.321162  4.228612   \n",
       "10  4.665979  4.741487  4.646986  4.559673  4.284008  4.312378  4.225003   \n",
       "11  4.663754  4.737903  4.642946  4.568484  4.281579  4.319957  4.224621   \n",
       "12  4.663619  4.739061  4.651961  4.586778  4.268772  4.324915  4.224811   \n",
       "13  4.665100  4.734181  4.648733  4.600241  4.271409  4.332584  4.221273   \n",
       "14  4.665383  4.725296  4.641176  4.608894  4.255402  4.333204  4.216415   \n",
       "15  4.709641  4.742804  4.658519  4.543219  4.253460  4.228101  4.157092   \n",
       "16  4.698521  4.739191  4.652665  4.548754  4.251203  4.230456  4.146784   \n",
       "17  4.696217  4.737129  4.648003  4.556075  4.248187  4.235888  4.138464   \n",
       "18  4.697104  4.735684  4.647111  4.570990  4.252269  4.246329  4.138485   \n",
       "19  4.698404  4.734125  4.643395  4.581351  4.249566  4.253631  4.133756   \n",
       "\n",
       "          7         8         9         10        11  \n",
       "0   4.087987  4.173543  4.257468  4.514432  4.414955  \n",
       "1   4.087243  4.171134  4.257544  4.509745  4.412368  \n",
       "2   4.088882  4.172706  4.260308  4.508608  4.411867  \n",
       "3   4.086651  4.172275  4.261654  4.508310  4.411677  \n",
       "4   4.085840  4.174062  4.264005  4.510499  4.413914  \n",
       "5   4.199530  4.292241  4.426102  4.671994  4.553437  \n",
       "6   4.187629  4.278012  4.414305  4.658885  4.542194  \n",
       "7   4.181122  4.265705  4.409812  4.651341  4.528942  \n",
       "8   4.170929  4.251718  4.403395  4.644707  4.517911  \n",
       "9   4.158962  4.238959  4.392817  4.636510  4.507975  \n",
       "10  4.177069  4.265076  4.421086  4.673464  4.540991  \n",
       "11  4.165707  4.249231  4.411282  4.660875  4.524203  \n",
       "12  4.157068  4.231308  4.398951  4.645172  4.506776  \n",
       "13  4.141382  4.209155  4.387005  4.633124  4.484800  \n",
       "14  4.124698  4.191792  4.372774  4.622047  4.468780  \n",
       "15  4.109575  4.220700  4.387587  4.643235  4.528277  \n",
       "16  4.093434  4.195589  4.368830  4.625434  4.505712  \n",
       "17  4.077472  4.172333  4.353811  4.608896  4.483943  \n",
       "18  4.066039  4.151629  4.341901  4.596337  4.463836  \n",
       "19  4.050708  4.127117  4.325795  4.580877  4.443470  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.07110105203070181)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = df_test[ori_col].values\n",
    "mean_squared_error(real, pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.05929291173832928)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive = [df_train[ori_col].iloc[-1].values] * test_size\n",
    "mean_squared_error(real, naive, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Mo</th>\n",
       "      <th>2 Mo</th>\n",
       "      <th>3 Mo</th>\n",
       "      <th>6 Mo</th>\n",
       "      <th>1 Yr</th>\n",
       "      <th>2 Yr</th>\n",
       "      <th>3 Yr</th>\n",
       "      <th>5 Yr</th>\n",
       "      <th>7 Yr</th>\n",
       "      <th>10 Yr</th>\n",
       "      <th>20 Yr</th>\n",
       "      <th>30 Yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <td>4.70</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18</th>\n",
       "      <td>4.70</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-19</th>\n",
       "      <td>4.67</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-20</th>\n",
       "      <td>4.68</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.66</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-21</th>\n",
       "      <td>4.72</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.36</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1 Mo  2 Mo  3 Mo  6 Mo  1 Yr  2 Yr  3 Yr  5 Yr  7 Yr  10 Yr  \\\n",
       "Date                                                                      \n",
       "2024-11-15  4.70  4.67  4.60  4.44  4.34  4.31  4.27  4.30  4.36   4.43   \n",
       "2024-11-18  4.70  4.65  4.63  4.44  4.33  4.29  4.25  4.28  4.35   4.42   \n",
       "2024-11-19  4.67  4.63  4.62  4.44  4.34  4.27  4.24  4.25  4.32   4.39   \n",
       "2024-11-20  4.68  4.63  4.62  4.44  4.37  4.31  4.26  4.28  4.34   4.41   \n",
       "2024-11-21  4.72  4.67  4.63  4.45  4.39  4.34  4.30  4.30  4.36   4.43   \n",
       "\n",
       "            20 Yr  30 Yr  \n",
       "Date                      \n",
       "2024-11-15   4.70   4.60  \n",
       "2024-11-18   4.70   4.61  \n",
       "2024-11-19   4.66   4.57  \n",
       "2024-11-20   4.66   4.59  \n",
       "2024-11-21   4.68   4.61  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[ori_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.66407683, 4.6880482 , 4.58706215, 4.49451238, 4.26064394,\n",
       "        4.201187  , 4.10178506, 4.08798675, 4.17354346, 4.25746796,\n",
       "        4.51443222, 4.41495509]),\n",
       " array([4.65792723, 4.68638298, 4.58311401, 4.49485415, 4.25686574,\n",
       "        4.20768825, 4.10373294, 4.08724269, 4.17113352, 4.25754362,\n",
       "        4.50974496, 4.41236799]),\n",
       " array([4.65596465, 4.6844064 , 4.58216824, 4.49543679, 4.25406714,\n",
       "        4.21491783, 4.10799169, 4.0888819 , 4.17270552, 4.26030764,\n",
       "        4.50860762, 4.41186676]),\n",
       " array([4.65393193, 4.68071803, 4.58079666, 4.49318703, 4.24684322,\n",
       "        4.21861217, 4.10869463, 4.0866514 , 4.17227466, 4.26165436,\n",
       "        4.50830992, 4.41167705]),\n",
       " array([4.65191622, 4.67728895, 4.57925671, 4.49220682, 4.24048311,\n",
       "        4.22277714, 4.11229057, 4.08584026, 4.17406209, 4.26400507,\n",
       "        4.51049918, 4.41391378])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4.76, 4.69, 4.58, 4.42, 4.3 , 4.13, 4.1 , 4.05, 4.1 , 4.18, 4.45,\n",
       "        4.36]),\n",
       " array([4.76, 4.69, 4.58, 4.42, 4.3 , 4.13, 4.1 , 4.05, 4.1 , 4.18, 4.45,\n",
       "        4.36]),\n",
       " array([4.76, 4.69, 4.58, 4.42, 4.3 , 4.13, 4.1 , 4.05, 4.1 , 4.18, 4.45,\n",
       "        4.36]),\n",
       " array([4.76, 4.69, 4.58, 4.42, 4.3 , 4.13, 4.1 , 4.05, 4.1 , 4.18, 4.45,\n",
       "        4.36]),\n",
       " array([4.76, 4.69, 4.58, 4.42, 4.3 , 4.13, 4.1 , 4.05, 4.1 , 4.18, 4.45,\n",
       "        4.36])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7 , 4.67, 4.6 , 4.44, 4.34, 4.31, 4.27, 4.3 , 4.36, 4.43, 4.7 ,\n",
       "        4.6 ],\n",
       "       [4.7 , 4.65, 4.63, 4.44, 4.33, 4.29, 4.25, 4.28, 4.35, 4.42, 4.7 ,\n",
       "        4.61],\n",
       "       [4.67, 4.63, 4.62, 4.44, 4.34, 4.27, 4.24, 4.25, 4.32, 4.39, 4.66,\n",
       "        4.57],\n",
       "       [4.68, 4.63, 4.62, 4.44, 4.37, 4.31, 4.26, 4.28, 4.34, 4.41, 4.66,\n",
       "        4.59],\n",
       "       [4.72, 4.67, 4.63, 4.45, 4.39, 4.34, 4.3 , 4.3 , 4.36, 4.43, 4.68,\n",
       "        4.61]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(0, 5):\n",
    "    if h == 0:\n",
    "        target_col = ori_col\n",
    "    else:\n",
    "        target_col = [f'{element}_+_{h}' for element in ori_col]\n",
    "    \n",
    "    feature_col = [element for element in all_cols if 'window' in element]\n",
    "\n",
    "    df_train_modified = df_train[:(len_train-h)]\n",
    "    df_test_modified = df_test.iloc[[0]]\n",
    "    print(len(df_train_modified))\n",
    "\n",
    "    X_train, y_train = df_train_modified[feature_col], df_train_modified[target_col]\n",
    "    X_test, y_test = df_test_modified[feature_col], df_test.iloc[h][ori_col]\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
