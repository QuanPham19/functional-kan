{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#@title 1.3. IMPORT LIBRARY\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "from credit_base import *\n",
    "from neural_net import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from kan import *\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv('/workspaces/functional-kan/phase_1/data/german_credit_data.csv')\n",
    "\n",
    "# Risk target\n",
    "df_credit['Risk'] = df_credit['Risk'].map({'good': 1, 'bad': 0})\n",
    "\n",
    "# Non-null savings and checking account\n",
    "encoder = LabelEncoder()\n",
    "non_nan_mask = df_credit['Saving accounts'].notna()\n",
    "df_credit.loc[non_nan_mask, 'Saving accounts'] = encoder.fit_transform(\n",
    "    df_credit.loc[non_nan_mask, 'Saving accounts']\n",
    ")\n",
    "\n",
    "non_nan_mask = df_credit['Checking account'].notna()\n",
    "df_credit.loc[non_nan_mask, 'Checking account'] = encoder.fit_transform(\n",
    "    df_credit.loc[non_nan_mask, 'Checking account']\n",
    ")\n",
    "\n",
    "# Sex \n",
    "df_credit['Sex'] = df_credit['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "# Monthly pay\n",
    "df_credit['Monthly pay'] = (df_credit[\"Credit amount\"] / df_credit[\"Duration\"])\n",
    "df_credit['Monthly pay'] = np.log(df_credit['Monthly pay'])\n",
    "\n",
    "# Age categorize\n",
    "df_credit['Age'] = df_credit['Age'].apply(age_categorize)\n",
    "\n",
    "# Housing categorize\n",
    "df_credit['Housing'] = df_credit['Housing'].apply(housing_categorize)\n",
    "\n",
    "# Purpose categorize\n",
    "df_credit['Purpose'] = df_credit['Purpose'].apply(purpose_categorize)\n",
    "\n",
    "# Credit amount\n",
    "df_credit[\"Credit amount\"] = np.log(df_credit[\"Credit amount\"])\n",
    "\n",
    "# Duration\n",
    "df_credit['Duration'] = np.log(df_credit['Duration'])\n",
    "\n",
    "X = df_credit.drop(columns='Risk')\n",
    "y = df_credit['Risk']\n",
    "\n",
    "# One-hot encoding for Age and Purpose\n",
    "X = pd.get_dummies(X, columns=['Age', 'Purpose', 'Housing'], dtype='int')\n",
    "X\n",
    "\n",
    "# KNN imputer\n",
    "# imputer = KNNImputer(n_neighbors=2)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Standard scaler\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Risk\n",
      "1    700\n",
      "0    300\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: Risk\n",
      "1    700\n",
      "0    700\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE Over-sampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Original class distribution:\", y.value_counts())\n",
    "print(\"Resampled class distribution:\", pd.Series(y_resampled).value_counts())\n",
    "\n",
    "df = pd.concat([X_resampled, y_resampled], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['train_input']), dim=1) == dataset['train_label']).type(dtype))\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['test_input']), dim=1) == dataset['test_label']).type(dtype))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "        probs_class_1 = probs[:, 1]  # Focus on class 1\n",
    "        targets = targets.double()\n",
    "        bce_loss = nn.BCELoss(reduction='none')(probs_class_1, targets)\n",
    "        pt = torch.where(targets == 1, probs_class_1, 1 - probs_class_1)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "criterion = FocalLoss(alpha=0.25, gamma=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 8.35e-01 | test_loss: 8.35e-01 | reg: 1.76e+01 | :   1%| | 3/250 [00:00<00:09, 26.17it"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.53e-01 | test_loss: 7.07e-01 | reg: 2.86e+01 | : 100%|█| 250/250 [00:07<00:00, 31.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold accuracy: (0.8758928571428571, 0.7714285714285715)\n",
      "Fold 2/5\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.46e-01 | test_loss: 7.61e-01 | reg: 2.99e+01 | : 100%|█| 250/250 [00:07<00:00, 32.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold accuracy: (0.8892857142857142, 0.7642857142857142)\n",
      "Fold 3/5\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.55e-01 | test_loss: 7.05e-01 | reg: 3.02e+01 | : 100%|█| 250/250 [00:07<00:00, 31.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold accuracy: (0.86875, 0.7678571428571429)\n",
      "Fold 4/5\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.68e-01 | test_loss: 7.64e-01 | reg: 2.88e+01 | : 100%|█| 250/250 [00:07<00:00, 32.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold accuracy: (0.8758928571428571, 0.7107142857142857)\n",
      "Fold 5/5\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.80e-01 | test_loss: 7.26e-01 | reg: 2.88e+01 | : 100%|█| 250/250 [00:07<00:00, 31.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n",
      "Fold accuracy: (0.8589285714285714, 0.7535714285714286)\n",
      "Average Train Accuracy: 0.8737\n",
      "Average Test Accuracy: 0.7536\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "n = df.shape[1] - 1\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Perform 5-fold stratified cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(df, df['Risk'])):\n",
    "    print(f\"Fold {fold+1}/{5}\")\n",
    "    \n",
    "    # Split the data for this fold\n",
    "    df_train, df_test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "    X_train, y_train = df_train.drop(columns='Risk'), df_train['Risk']\n",
    "    X_test, y_test = df_test.drop(columns='Risk'), df_test['Risk']\n",
    "    \n",
    "    # Prepare the dataset\n",
    "    dataset = dict()\n",
    "    dtype = torch.get_default_dtype()\n",
    "    dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "    dataset['train_label'] = torch.from_numpy(y_train.values).type(torch.long).to(device)\n",
    "    dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype).to(device)\n",
    "    dataset['test_label'] = torch.from_numpy(y_test.values).type(torch.long).to(device)\n",
    "\n",
    "    # Initialize model\n",
    "    model = KAN(width=[n, 6, 2], grid=5, k=2, seed=42, device=device)\n",
    "\n",
    "    # Train the model and evaluate it\n",
    "    results = model.fit(dataset, opt=\"Adam\", steps=250, lr=0.002, lamb=0.001, metrics=(train_acc, test_acc), loss_fn=torch.nn.CrossEntropyLoss())\n",
    "\n",
    "    print(f'Fold accuracy: {results['train_acc'][-1], results['test_acc'][-1]}')\n",
    "    \n",
    "    train_accuracies.append(results['train_acc'][-1])\n",
    "    test_accuracies.append(results['test_acc'][-1])\n",
    "\n",
    "# Output the average accuracies\n",
    "print(f\"Average Train Accuracy: {torch.mean(torch.tensor(train_accuracies)):.4f}\")\n",
    "print(f\"Average Test Accuracy: {torch.mean(torch.tensor(test_accuracies)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
