{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from kan import *\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FKAN(KAN):\n",
    "    def __init__(self, in_func, out_func, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.in_func = in_func\n",
    "        self.out_func = out_func \n",
    "\n",
    "    def forward(self, x, singularity_avoiding=False, y_th=10.):\n",
    "        x = points_to_curve_2d(x)\n",
    "        print(x.shape)\n",
    "\n",
    "        x = x[:,self.input_id.long()]\n",
    "        assert x.shape[1] == self.width_in[0]\n",
    "        \n",
    "        # cache data\n",
    "        self.cache_data = x\n",
    "        \n",
    "        self.acts = []  # shape ([batch, n0], [batch, n1], ..., [batch, n_L])\n",
    "        self.acts_premult = []\n",
    "        self.spline_preacts = []\n",
    "        self.spline_postsplines = []\n",
    "        self.spline_postacts = []\n",
    "        self.acts_scale = []\n",
    "        self.acts_scale_spline = []\n",
    "        self.subnode_actscale = []\n",
    "        self.edge_actscale = []\n",
    "        # self.neurons_scale = []\n",
    "\n",
    "        self.acts.append(x)  # acts shape: (batch, width[l])\n",
    "\n",
    "        for l in range(self.depth):\n",
    "            \n",
    "            x_numerical, preacts, postacts_numerical, postspline = self.act_fun[l](x)\n",
    "            #print(preacts, postacts_numerical, postspline)\n",
    "            \n",
    "            if self.symbolic_enabled == True:\n",
    "                x_symbolic, postacts_symbolic = self.symbolic_fun[l](x, singularity_avoiding=singularity_avoiding, y_th=y_th)\n",
    "            else:\n",
    "                x_symbolic = 0.\n",
    "                postacts_symbolic = 0.\n",
    "\n",
    "            x = x_numerical + x_symbolic\n",
    "            \n",
    "            if self.save_act:\n",
    "                # save subnode_scale\n",
    "                self.subnode_actscale.append(torch.std(x, dim=0).detach())\n",
    "            \n",
    "            # subnode affine transform\n",
    "            x = self.subnode_scale[l][None,:] * x + self.subnode_bias[l][None,:]\n",
    "            \n",
    "            if self.save_act:\n",
    "                postacts = postacts_numerical + postacts_symbolic\n",
    "\n",
    "                # self.neurons_scale.append(torch.mean(torch.abs(x), dim=0))\n",
    "                #grid_reshape = self.act_fun[l].grid.reshape(self.width_out[l + 1], self.width_in[l], -1)\n",
    "                input_range = torch.std(preacts, dim=0) + 0.1\n",
    "                output_range_spline = torch.std(postacts_numerical, dim=0) # for training, only penalize the spline part\n",
    "                output_range = torch.std(postacts, dim=0) # for visualization, include the contribution from both spline + symbolic\n",
    "                # save edge_scale\n",
    "                self.edge_actscale.append(output_range)\n",
    "                \n",
    "                self.acts_scale.append((output_range / input_range).detach())\n",
    "                self.acts_scale_spline.append(output_range_spline / input_range)\n",
    "                self.spline_preacts.append(preacts.detach())\n",
    "                self.spline_postacts.append(postacts.detach())\n",
    "                self.spline_postsplines.append(postspline.detach())\n",
    "\n",
    "                self.acts_premult.append(x.detach())\n",
    "            \n",
    "            # multiplication\n",
    "            dim_sum = self.width[l+1][0]\n",
    "            dim_mult = self.width[l+1][1]\n",
    "            \n",
    "            if self.mult_homo == True:\n",
    "                for i in range(self.mult_arity-1):\n",
    "                    if i == 0:\n",
    "                        x_mult = x[:,dim_sum::self.mult_arity] * x[:,dim_sum+1::self.mult_arity]\n",
    "                    else:\n",
    "                        x_mult = x_mult * x[:,dim_sum+i+1::self.mult_arity]\n",
    "                        \n",
    "            else:\n",
    "                for j in range(dim_mult):\n",
    "                    acml_id = dim_sum + np.sum(self.mult_arity[l+1][:j])\n",
    "                    for i in range(self.mult_arity[l+1][j]-1):\n",
    "                        if i == 0:\n",
    "                            x_mult_j = x[:,[acml_id]] * x[:,[acml_id+1]]\n",
    "                        else:\n",
    "                            x_mult_j = x_mult_j * x[:,[acml_id+i+1]]\n",
    "                            \n",
    "                    if j == 0:\n",
    "                        x_mult = x_mult_j\n",
    "                    else:\n",
    "                        x_mult = torch.cat([x_mult, x_mult_j], dim=1)\n",
    "                \n",
    "            if self.width[l+1][1] > 0:\n",
    "                x = torch.cat([x[:,:dim_sum], x_mult], dim=1)\n",
    "            \n",
    "            # x = x + self.biases[l].weight\n",
    "            # node affine transform\n",
    "            x = self.node_scale[l][None,:] * x + self.node_bias[l][None,:]\n",
    "            \n",
    "            self.acts.append(x.detach())\n",
    "            \n",
    "        \n",
    "        return x\n",
    "\n",
    "model = FKAN(in_func=1, out_func=2, width=[2,5,1], grid=5, k=3, seed=0, auto_save=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3894, 2.4568, 2.7025, 2.4719, 2.4394, 2.7923, 2.8368, 2.9696],\n",
       "        [2.4128, 2.4333, 2.5666, 2.3720, 2.3085, 2.7087, 2.7519, 2.9195],\n",
       "        [2.3942, 2.4775, 2.6361, 2.4895, 2.4303, 2.8253, 2.8137, 2.9796],\n",
       "        [2.4048, 2.5211, 2.6265, 2.5251, 2.4753, 2.8435, 2.8576, 2.9896],\n",
       "        [2.3924, 2.5376, 2.6320, 2.5856, 2.5348, 2.8330, 2.8979, 2.9995]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = treasury_data_retrieval('us_treasury_rates_large.csv').head()\n",
    "\n",
    "dtype = torch.get_default_dtype()\n",
    "\n",
    "points_to_curve_2d(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Mo</th>\n",
       "      <th>2 Mo</th>\n",
       "      <th>3 Mo</th>\n",
       "      <th>6 Mo</th>\n",
       "      <th>1 Yr</th>\n",
       "      <th>2 Yr</th>\n",
       "      <th>3 Yr</th>\n",
       "      <th>5 Yr</th>\n",
       "      <th>7 Yr</th>\n",
       "      <th>10 Yr</th>\n",
       "      <th>...</th>\n",
       "      <th>3 Mo_-_1_window_5</th>\n",
       "      <th>6 Mo_-_1_window_5</th>\n",
       "      <th>1 Yr_-_1_window_5</th>\n",
       "      <th>2 Yr_-_1_window_5</th>\n",
       "      <th>3 Yr_-_1_window_5</th>\n",
       "      <th>5 Yr_-_1_window_5</th>\n",
       "      <th>7 Yr_-_1_window_5</th>\n",
       "      <th>10 Yr_-_1_window_5</th>\n",
       "      <th>20 Yr_-_1_window_5</th>\n",
       "      <th>30 Yr_-_1_window_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-12-02</th>\n",
       "      <td>4.75</td>\n",
       "      <td>4.63</td>\n",
       "      <td>4.51</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.08</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>...</td>\n",
       "      <td>4.608</td>\n",
       "      <td>4.444</td>\n",
       "      <td>4.360</td>\n",
       "      <td>4.222</td>\n",
       "      <td>4.202</td>\n",
       "      <td>4.160</td>\n",
       "      <td>4.214</td>\n",
       "      <td>4.282</td>\n",
       "      <td>4.546</td>\n",
       "      <td>4.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-03</th>\n",
       "      <td>4.66</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.27</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.23</td>\n",
       "      <td>...</td>\n",
       "      <td>4.584</td>\n",
       "      <td>4.438</td>\n",
       "      <td>4.336</td>\n",
       "      <td>4.182</td>\n",
       "      <td>4.160</td>\n",
       "      <td>4.116</td>\n",
       "      <td>4.170</td>\n",
       "      <td>4.238</td>\n",
       "      <td>4.504</td>\n",
       "      <td>4.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-04</th>\n",
       "      <td>4.65</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.47</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.19</td>\n",
       "      <td>...</td>\n",
       "      <td>4.558</td>\n",
       "      <td>4.426</td>\n",
       "      <td>4.316</td>\n",
       "      <td>4.174</td>\n",
       "      <td>4.144</td>\n",
       "      <td>4.104</td>\n",
       "      <td>4.162</td>\n",
       "      <td>4.230</td>\n",
       "      <td>4.498</td>\n",
       "      <td>4.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-05</th>\n",
       "      <td>4.59</td>\n",
       "      <td>4.53</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.530</td>\n",
       "      <td>4.412</td>\n",
       "      <td>4.288</td>\n",
       "      <td>4.158</td>\n",
       "      <td>4.120</td>\n",
       "      <td>4.084</td>\n",
       "      <td>4.140</td>\n",
       "      <td>4.208</td>\n",
       "      <td>4.476</td>\n",
       "      <td>4.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-06</th>\n",
       "      <td>4.57</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.03</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.15</td>\n",
       "      <td>...</td>\n",
       "      <td>4.502</td>\n",
       "      <td>4.402</td>\n",
       "      <td>4.266</td>\n",
       "      <td>4.150</td>\n",
       "      <td>4.106</td>\n",
       "      <td>4.076</td>\n",
       "      <td>4.130</td>\n",
       "      <td>4.192</td>\n",
       "      <td>4.458</td>\n",
       "      <td>4.360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 288 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1 Mo  2 Mo  3 Mo  6 Mo  1 Yr  2 Yr  3 Yr  5 Yr  7 Yr  10 Yr  ...  \\\n",
       "Date                                                                     ...   \n",
       "2024-12-02  4.75  4.63  4.51  4.43  4.30  4.17  4.11  4.08  4.13   4.19  ...   \n",
       "2024-12-03  4.66  4.56  4.49  4.40  4.27  4.17  4.13  4.11  4.17   4.23  ...   \n",
       "2024-12-04  4.65  4.54  4.47  4.38  4.23  4.13  4.09  4.07  4.13   4.19  ...   \n",
       "2024-12-05  4.59  4.53  4.46  4.38  4.23  4.15  4.10  4.07  4.12   4.17  ...   \n",
       "2024-12-06  4.57  4.50  4.42  4.34  4.19  4.10  4.05  4.03  4.09   4.15  ...   \n",
       "\n",
       "            3 Mo_-_1_window_5  6 Mo_-_1_window_5  1 Yr_-_1_window_5  \\\n",
       "Date                                                                  \n",
       "2024-12-02              4.608              4.444              4.360   \n",
       "2024-12-03              4.584              4.438              4.336   \n",
       "2024-12-04              4.558              4.426              4.316   \n",
       "2024-12-05              4.530              4.412              4.288   \n",
       "2024-12-06              4.502              4.402              4.266   \n",
       "\n",
       "            2 Yr_-_1_window_5  3 Yr_-_1_window_5  5 Yr_-_1_window_5  \\\n",
       "Date                                                                  \n",
       "2024-12-02              4.222              4.202              4.160   \n",
       "2024-12-03              4.182              4.160              4.116   \n",
       "2024-12-04              4.174              4.144              4.104   \n",
       "2024-12-05              4.158              4.120              4.084   \n",
       "2024-12-06              4.150              4.106              4.076   \n",
       "\n",
       "            7 Yr_-_1_window_5  10 Yr_-_1_window_5  20 Yr_-_1_window_5  \\\n",
       "Date                                                                    \n",
       "2024-12-02              4.214               4.282               4.546   \n",
       "2024-12-03              4.170               4.238               4.504   \n",
       "2024-12-04              4.162               4.230               4.498   \n",
       "2024-12-05              4.140               4.208               4.476   \n",
       "2024-12-06              4.130               4.192               4.458   \n",
       "\n",
       "            30 Yr_-_1_window_5  \n",
       "Date                            \n",
       "2024-12-02               4.466  \n",
       "2024-12-03               4.418  \n",
       "2024-12-04               4.408  \n",
       "2024-12-05               4.382  \n",
       "2024-12-06               4.360  \n",
       "\n",
       "[5 rows x 288 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = treasury_data_retrieval('us_treasury_rates_large.csv')\n",
    "data, ori_col = full_df_retrieval(df)\n",
    "all_cols = data.columns\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-sample test size, diff between sliding element = test size\n",
    "test_size = 1\n",
    "sliding_list = range(10, -1, -1)\n",
    "\n",
    "# Set variables for cross-validation\n",
    "truth_df = pd.DataFrame()\n",
    "naive_df = pd.DataFrame()\n",
    "kan_df = pd.DataFrame()\n",
    "\n",
    "# Loop over sliding windows\n",
    "for sliding in sliding_list:\n",
    "    \n",
    "    # Trim original data by sliding window size\n",
    "    df = data[:len(data)-sliding]\n",
    "\n",
    "    # Use 2 years of data (500 days) for training\n",
    "    df_train, df_test = df[-test_size-250:-test_size], df[-test_size:]\n",
    "    len_train = len(df_train)\n",
    "\n",
    "    # Append to truth dataframe, if multi-step drop iloc\n",
    "    truth_df = pd.concat([truth_df, df_test[ori_col].iloc[[-1], :]], axis=0, ignore_index=False)\n",
    "\n",
    "    # Append to naive dataframe, if multi-step change 1 to test_size\n",
    "    naive_element = pd.DataFrame([df_train[ori_col].iloc[-1].values] * 1)\n",
    "    naive_df = pd.concat([naive_df, naive_element], axis=0, ignore_index=True)\n",
    "\n",
    "    # Initialize predictions array\n",
    "    pred = list()\n",
    "\n",
    "    # To predict multi-step use range, to predict only h-ahead-step use equal\n",
    "    # for h in range(test_size):\n",
    "    for h in [test_size - 1]:\n",
    "        # Print checkpoints\n",
    "        print(f'LAST DAY OF DATASET: {-sliding}, FUTURE STEPS: {h+1}')\n",
    "\n",
    "        # If h = 0 target columns unchanged\n",
    "        if h == 0:  \n",
    "            target_col = ori_col\n",
    "        # If h > 0 target columns modified\n",
    "        else:       \n",
    "            target_col = [f'{element}_+_{h}' for element in ori_col]\n",
    "        \n",
    "        # Extract feature columns\n",
    "        feature_col = [element for element in all_cols if 'window' in element]\n",
    "\n",
    "        # Cut train data due to direct forecast\n",
    "        df_train_modified = df_train[:(len_train-h)]\n",
    "\n",
    "        # Test data is the first row \n",
    "        df_test_modified = df_test.iloc[[0]]\n",
    "        print(len(df_train_modified))\n",
    "\n",
    "        X_train, y_train = df_train_modified[feature_col], df_train_modified[target_col]\n",
    "        X_test, y_test = df_test_modified[feature_col], df_test.iloc[h][ori_col]\n",
    "\n",
    "        X_concat = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "        n_inputs = X_train.shape[1]\n",
    "        n_outputs = y_train.shape[1]\n",
    "\n",
    "        dataset = dict()\n",
    "        dtype = torch.get_default_dtype()\n",
    "        dataset['train_input'] = torch.from_numpy(X_train.values).type(dtype).to(device)\n",
    "        dataset['train_label'] = torch.from_numpy(y_train.values).type(dtype).to(device)\n",
    "        dataset['test_input'] = torch.from_numpy(X_test.values).type(dtype).to(device)\n",
    "        dataset['test_label'] = torch.from_numpy(y_test.values).type(dtype).to(device)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = FKAN(width=[8, 32, n_outputs], grid=5, k=2, seed=42, device=device, symbolic_enabled=False, save_act=False, auto_save=False, in_func=None, out_func=None)\n",
    "\n",
    "        # Train the model and compute metrics\n",
    "        results = model.fit(dataset, opt=\"Adam\", lr=0.005, steps=500, update_grid=False)\n",
    "\n",
    "        # loss_fn = loss_fn_eval = lambda x, y: torch.mean((x - y) ** 2)\n",
    "        # p = \n",
    "        # train_loss = loss_fn(p, dataset['train_label'])\n",
    "        # print(train_loss)\n",
    "        # torch.sqrt(train_loss).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        pred.append(model.forward(dataset['test_input']).cpu().detach().numpy().flatten())\n",
    "        # print(n_inputs, n_outputs)\n",
    "\n",
    "    kan_element = pd.DataFrame(pred)\n",
    "    kan_df = pd.concat([kan_element, kan_df], axis=0, ignore_index=True)\n",
    "\n",
    "# df_train_modified\n",
    "# df_test_modified\n",
    "# y_train\n",
    "# X_test\n",
    "# model(dataset['test_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
