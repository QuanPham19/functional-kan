{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "\n",
    "        # Self initialize is required for using nn.Module\n",
    "        super(CustomLinear, self).__init__()\n",
    "\n",
    "        # Initialize weights and biases and flag as params by nn.Parameter\n",
    "        self.weight = torch.nn.Parameter(torch.randn(input_size, output_size))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Execute a forward pass in a single layer\n",
    "        return x @ self.weight + self.bias\n",
    "\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, width):\n",
    "\n",
    "        # Self initialize is required for using nn.Module\n",
    "        super(CustomNet, self).__init__()\n",
    "\n",
    "        # Initialize empty layer list\n",
    "        self.list_layers = []\n",
    "\n",
    "        # Number of layers \n",
    "        n_layers = len(width) - 1\n",
    "\n",
    "        # Append each layer to layer list\n",
    "        for id in range(n_layers):\n",
    "            input_size, output_size = width[id], width[id+1]\n",
    "            self.list_layers.append(CustomLinear(input_size, output_size))\n",
    "\n",
    "        # Modify list layer to ModuleList object\n",
    "        self.list_layers = nn.ModuleList(self.list_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Execute forward pass and ReLU in each layer except last\n",
    "        for layer in self.list_layers[:-1]:\n",
    "            x = layer.forward(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # Only execute forward pass in the last layer\n",
    "        x = self.list_layers[-1].forward(x)\n",
    "        # x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0707,  0.2669],\n",
       "        [ 0.5908, -0.8883],\n",
       "        [ 0.1134,  0.5694],\n",
       "        [ 0.4948, -0.4567],\n",
       "        [-0.1629,  0.2921],\n",
       "        [ 0.4560, -0.7879],\n",
       "        [ 0.6345, -1.2023],\n",
       "        [ 0.5387, -0.2367]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CustomNet([3, 5, 2])\n",
    "torch.manual_seed(0)\n",
    "X = torch.rand(1000, 3)  # 1000 samples, 3 features each\n",
    "y = torch.randint(0, 2, (1000,))  # Binary classification (0 or 1)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "dataloader\n",
    "\n",
    "model = CustomNet([3, 6, 2])\n",
    "\n",
    "for batch_X, batch_y in dataloader:\n",
    "    # Forward pass\n",
    "    predictions = model.forward(batch_X)\n",
    "    \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc():\n",
    "    return torch.mean((torch.argmax(model(dataset['test_input']), dim=1) == dataset['test_label']).type(dtype))\n",
    "\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    # Apply softmax to predictions and calculate log probabilities\n",
    "    log_probs = F.log_softmax(predictions, dim=1)\n",
    "    return -torch.mean(log_probs[torch.arange(len(targets)), targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.6945\n",
      "Epoch [40/100], Loss: 0.6940\n",
      "Epoch [60/100], Loss: 0.6928\n",
      "Epoch [80/100], Loss: 0.6915\n",
      "Epoch [100/100], Loss: 0.6913\n",
      "Accuracy: 0.5300\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 3\n",
    "hidden_size = 5\n",
    "output_size = 2\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Generate synthetic data for demonstration\n",
    "torch.manual_seed(0)\n",
    "X = torch.rand(1000, input_size)  # 1000 samples, 3 features each\n",
    "y = torch.randint(0, output_size, (1000,))  # Binary classification (0 or 1)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = CustomNet([input_size, hidden_size, output_size])\n",
    "\n",
    "# Define loss function\n",
    "def loss_fn(predictions, targets, type='classification'):\n",
    "    \n",
    "    # Cross-entropy if classification\n",
    "    if type == 'classification':\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Mean squared error if regression \n",
    "    elif type == 'regression':\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    return loss_fn(predictions, targets)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        # Forward pass\n",
    "        predictions = model.forward(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(predictions, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters manually\n",
    "        with torch.no_grad():  # Disable gradient tracking during updates\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad  # Gradient descent\n",
    "                param.grad.zero_()  # Reset gradients after updating\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if epoch % 20 == (20-1):\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Evaluation mode\n",
    "model.eval = True\n",
    "with torch.no_grad():\n",
    "    predictions = model.forward(X)\n",
    "    _, predicted_classes = torch.max(predictions, 1)\n",
    "    accuracy = (predicted_classes == y).float().mean()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3952, -0.0571, -0.4534,  0.0934,  0.3414],\n",
       "         [ 0.3043, -0.0950,  0.7846, -0.3401, -0.1687],\n",
       "         [ 0.1813,  0.3657, -0.9579, -0.0737, -0.2886]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0771,  0.0107, -0.4503, -0.0901, -0.2612], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.3313,  0.5072],\n",
       "         [-0.6385, -1.1488],\n",
       "         [-0.2219,  2.1029],\n",
       "         [ 2.2959, -0.2719],\n",
       "         [ 1.4996, -0.5152]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1288, -0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
